{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4c5a136-e872-4846-9965-9ddc5251a0b3",
   "metadata": {},
   "source": [
    "# NYC Apartment Search\n",
    "\n",
    "_[Project prompt](https://docs.google.com/document/d/1BYVyFBDcTywdUlanH0ysfOrNWPgl7UkqXA7NeewTzxA/edit#heading=h.bpxu7uvknnbk)_\n",
    "\n",
    "_This scaffolding notebook may be used to help setup your final project. It's **totally optional** whether you make use of this or not._\n",
    "\n",
    "_If you do use this notebook, everything provided is optional as well - you may remove or add code as you wish._\n",
    "\n",
    "_**All code below should be consider \"pseudo-code\" - not functional by itself, and only an idea of a possible approach.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf11fa0-4684-4f5e-8048-0f4cc5f4f243",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f675d4b-794e-407c-aac9-b85c4a3975d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All import statements needed for the project, for example:\n",
    "\n",
    "from geopandas import GeoDataFrame\n",
    "import pathlib\n",
    "from requests.exceptions import ReadTimeout\n",
    "import time\n",
    "import geoalchemy2 as gdb\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import sqlalchemy as db\n",
    "from sodapy import Socrata\n",
    "import glob\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine,text\n",
    "from sqlalchemy.orm import declarative_base\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from shapely.geometry import Point, Polygon\n",
    "import unittest\n",
    "from datetime import date\n",
    "from sqlalchemy.dialects.postgresql import insert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a62277-51cf-48a2-81d2-9b2127088a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any constants you might need; some have been added for you\n",
    "\n",
    "# Where data files will be read from/written to - this should already exist\n",
    "DATA_DIR = pathlib.Path(\"data\")\n",
    "ZIPCODE_DATA_FILE = DATA_DIR / \"nyc_zipcodes.shp\"\n",
    "ZILLOW_DATA_FILE = DATA_DIR / \"zillow_rent_data.csv\"\n",
    "\n",
    "NYC_DATA_APP_TOKEN = \"xX3rCbSDM4vF0QEfgh09b2ZWW\"\n",
    "BASE_NYC_DATA_URL = \"https://data.cityofnewyork.us/\"\n",
    "NYC_DATA_311 = \"erm2-nwe9.geojson\"\n",
    "NYC_DATA_TREES = \"5rq2-4hqu.geojson\"\n",
    "\n",
    "DB_NAME = \"IEOR4501-XL\"\n",
    "\n",
    "DB_USER = \"postgres\"\n",
    "#DB_URL = f\"postgres+psycopg2://{DB_USER}@localhost/{DB_NAME}\"\n",
    "DB_URL = f\"postgresql://{DB_USER}@localhost/{DB_NAME}\"\n",
    "DB_SCHEMA_FILE = \"schema.sql\"\n",
    "\n",
    "QUERY_DIR = pathlib.Path(\"queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd67cca9-ec72-44e3-83b8-b65f1ed5bb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the QUERY_DIRECTORY exists\n",
    "if not QUERY_DIR.exists():\n",
    "    QUERY_DIR.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52476a07-9bf2-4b7a-8cb7-93648bb4d303",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f651ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloading data from small chunks\n",
    "def download_nyc_csv_data (year:int, starttime:str, endtime:str, url:str, filename:str ) -> str:\n",
    "\n",
    "    filepath = f'{DATA_DIR}/{filename}_{year}.csv'\n",
    "    query=f\"\"\"\n",
    "    select * \n",
    "    where created_date between {starttime} \n",
    "    and {endtime}\n",
    "    \"\"\"\n",
    "\n",
    "    if not filename:\n",
    "        print(f\"Downloading {url} to {filename}...\")\n",
    "        client = Socrata( \"data.cityofnewyork.us\",\n",
    "                  \"xX3rCbSDM4vF0QEfgh09b2ZWW\",\n",
    "                  username=\"yirong263@gmail.com\",\n",
    "                  password=\"UTDYnmz*zn2u3g6\",\n",
    "                  timeout=60)\n",
    "        max_retries = 5\n",
    "        retry_wait = 10  # Initial wait time in seconds\n",
    "\n",
    "        while max_retries > 0:\n",
    "            try:    \n",
    "            # Set initial parameters for the SoQL query\n",
    "                limit = 1000000  # Example limit\n",
    "                offset = 0  # Start at the beginning\n",
    "                total_records = 100000000  # Example total number of records you wish to download\n",
    "                current_record = 0\n",
    "                while current_record < total_records:\n",
    "                    # Adjust the query to include the limit and offset\n",
    "                    results = client.get(f\"{url}\",query= query+ f\" limit {limit} offset {offset}\")\n",
    "                    \n",
    "                    # Convert to DataFrame and save to CSV\n",
    "                    df = pd.DataFrame.from_records(results)\n",
    "                    df.to_csv(f'{filepath}', index=False)\n",
    "                    \n",
    "                    # Update the offset and current_record count\n",
    "                    offset += limit\n",
    "                    current_record += len(results)\n",
    "\n",
    "                    # Optional: Print progress\n",
    "                    print(f'Downloaded {current_record} of {total_records}')\n",
    "                break\n",
    "            \n",
    "            except ReadTimeout:\n",
    "                # Wait before retrying\n",
    "                time.sleep(retry_wait)\n",
    "\n",
    "                # Reduce the number of retries left\n",
    "\n",
    "                max_retries -= 1\n",
    "                # Increase the wait time for the next retry\n",
    "                \n",
    "                retry_wait *= 2\n",
    "        \n",
    "        print(f\"Done downloading {url} from {year}.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Reading from {filepath}...\")\n",
    "\n",
    "\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f720e660",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unit test\n",
    "download_nyc_csv_data (2015,\"2015-01-01T00:00:00.000\",\"2015-12-31T23:59:59.999\",\"erm2-nwe9\",'nyc_311_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee245240-2fbb-45b8-9a92-4e2368f62c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_zipcodes(zipcode_datafile: str) -> GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Load and clean NYC zipcode data from a shapefile.\n",
    "    Args:\n",
    "    zipcode_datafile (str): The file path to the shapefile.\n",
    "    \n",
    "    Returns:\n",
    "    GeoDataFrame: Cleaned geospatial data frame of NYC zipcodes.\n",
    "    \"\"\"\n",
    "    # Load the shapefile using GeoPandas\n",
    "    gdf = gpd.read_file(zipcode_datafile)\n",
    "    \n",
    "    # Remove unnecessary columns from the dataframe and invalid data\n",
    "    columns_to_drop = ['BLDGZIP', 'STATE', 'ST_FIPS', 'CTY_FIPS', 'URL', 'SHAPE_AREA', 'SHAPE_LEN']\n",
    "    gdf_cleaned = gdf.drop(columns=columns_to_drop)\n",
    "    gdf.drop_duplicates(subset='ZIPCODE', keep='first', inplace=True)\n",
    "    gdf.dropna(inplace=True)\n",
    "    gdf.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    gdf_cleaned = gdf_cleaned.rename(columns={'PO_NAME': 'City'})\n",
    "\n",
    "    # Set the coordinate reference system to EPSG 4326\n",
    "    gdf_cleaned = gdf_cleaned.to_crs(epsg=4326)\n",
    "\n",
    "    # Normalize column names and change the datatype\n",
    "    gdf_cleaned.columns = [column_name.lower().replace(' ', '_') for column_name in gdf_cleaned.columns]\n",
    "    gdf_cleaned['zipcode']=gdf_cleaned['zipcode'].astype(float).astype(int)\n",
    "    gdf_cleaned['population']=gdf_cleaned['population'].astype(float).astype(int)\n",
    "\n",
    "    return gdf_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8a2e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unit test\n",
    "load_and_clean_zipcodes(ZIPCODE_DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed2a5a9-1027-4c41-bbb5-039c32ce7e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_clean_311_data()-> GeoDataFrame:\n",
    "    #data downloading\n",
    "    download_nyc_csv_data(2015,\"2015-01-01T00:00:00.000\",\"2015-12-31T23:59:59.999\",\"erm2-nwe9\",'nyc_311_data')\n",
    "    download_nyc_csv_data(2016,\"2016-01-01T00:00:00.000\",\"2016-12-31T23:59:59.999\",\"erm2-nwe9\",'nyc_311_data')\n",
    "    download_nyc_csv_data(2017,\"2017-01-01T00:00:00.000\",\"2017-12-31T23:59:59.999\",\"erm2-nwe9\",'nyc_311_data')\n",
    "    download_nyc_csv_data(2018,\"2018-01-01T00:00:00.000\",\"2018-12-31T23:59:59.999\",\"erm2-nwe9\",'nyc_311_data')\n",
    "    download_nyc_csv_data(2019,\"2019-01-01T00:00:00.000\",\"2019-12-31T23:59:59.999\",\"erm2-nwe9\",'nyc_311_data')\n",
    "    download_nyc_csv_data(2020,\"2020-01-01T00:00:00.000\",\"2020-12-31T23:59:59.999\",\"erm2-nwe9\",'nyc_311_data')\n",
    "    download_nyc_csv_data(2021,\"2021-01-01T00:00:00.000\",\"2021-12-31T23:59:59.999\",\"erm2-nwe9\",'nyc_311_data')\n",
    "    download_nyc_csv_data(2022,\"2022-01-01T00:00:00.000\",\"2022-12-31T23:59:59.999\",\"erm2-nwe9\",'nyc_311_data')\n",
    "    download_nyc_csv_data(2023,\"2023-01-01T00:00:00.000\",\"2015-09-30T23:59:59.999\",\"erm2-nwe9\",'nyc_311_data')\n",
    "\n",
    "    # After downloading all chunks\n",
    "    csv_files = glob.glob('data/nyc_311_data_*.csv')\n",
    "    \n",
    "    # Remove unnecessary columns by keeping only the ones you need for each file\n",
    "    dfs=[]\n",
    "    for file in csv_files:\n",
    "        df=pd.read_csv(file)\n",
    "        columns_needed = ['unique_key', 'created_date', 'complaint_type','incident_zip','latitude', 'longitude']  # Replace with actual column names\n",
    "        df = df[columns_needed]\n",
    "\n",
    "        #eliminate duplicate\n",
    "        df.drop_duplicates(inplace=True)\n",
    "\n",
    "        # Remove invalid data points\n",
    "        df.dropna(inplace=True) \n",
    "\n",
    "        # Normalize column names\n",
    "        df.columns = [column_name.lower().replace(' ', '_') for column_name in df.columns]\n",
    "\n",
    "        dfs.append(df) # processed df and append to a list\n",
    "\n",
    "    # Concatenate all DataFrames into one\n",
    "    NYC311_df = pd.concat(dfs,ignore_index=True)\n",
    "    NYC311_df.drop_duplicates(inplace=True)# header duplicate elimination\n",
    "    NYC311_df = NYC311_df.drop_duplicates(subset=['unique_key'])\n",
    "\n",
    "    # Normalize Column Types\n",
    "    # unique_key \n",
    "    NYC311_df['unique_key'] = NYC311_df['unique_key'].astype(int)\n",
    "\n",
    "    # change name into 'id_NYC311'\n",
    "    NYC311_df.rename(columns={'unique_key': 'id_NYC311'}, inplace=True)\n",
    "\n",
    "    #incident zip\n",
    "    NYC311_df.rename(columns={'incident_zip': 'zipcode'}, inplace=True)\n",
    "    NYC311_df['zipcode']=NYC311_df['zipcode'].astype(float).astype(int)\n",
    "    NYC311_df = NYC311_df[NYC311_df['zipcode'].apply(lambda x: str(x).isdigit() and len(str(x)) == 5)] \n",
    "\n",
    "    #created_date\n",
    "    NYC311_df.rename(columns={'created_date': 'date'}, inplace=True)#rename \"date\"\n",
    "    NYC311_df = NYC311_df.sort_values(by='date')# sorting by date\n",
    "    NYC311_df['date'] = pd.to_datetime(NYC311_df['date']).dt.strftime('%Y-%m-%d')#change date format into yyyy-mm-dd\n",
    "        \n",
    "    # Assuming df is your existing DataFrame with latitude and longitude columns\n",
    "    NYC311_df = gpd.GeoDataFrame(NYC311_df, geometry=gpd.points_from_xy(NYC311_df['longitude'], NYC311_df['latitude']))\n",
    "    NYC311_df.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "    #save the combined DataFrame to a new CSV file\n",
    "    # NYC311_df.to_csv('data/nyc_311_data.csv', index=False)\n",
    "    return NYC311_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6829d8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unit test\n",
    "download_and_clean_311_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c4b1bc-c841-4b87-8301-1dc2cafeccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_clean_tree_data() -> GeoDataFrame:\n",
    "    download_nyc_csv_data(2015,\"2015-01-01T00:00:00.000\",\"2015-12-31T23:59:59.999\",\"5rq2-4hqu\",'tree')\n",
    "    tree_df=pd.read_csv('data/tree_2015.csv')\n",
    "    # Remove unnecessary columns by keeping only the ones you need\n",
    "    columns_needed = ['created_at', 'tree_id', 'status','zipcode','health','spc_common', 'latitude', 'longitude']  # Replace with actual column names\n",
    "    tree_df = tree_df[columns_needed]\n",
    "\n",
    "    # Remove invalid data points\n",
    "    # This is highly dependent on the context of your data, but as an example:\n",
    "    tree_df.drop_duplicates(inplace=True)\n",
    "    tree_df.dropna(inplace=True)  \n",
    "\n",
    "    # Normalize column names\n",
    "    tree_df.columns = [column_name.lower().replace(' ', '_') for column_name in tree_df.columns]\n",
    "    #created_at\n",
    "    tree_df.rename(columns={'created_at': 'date'}, inplace=True)\n",
    "    tree_df['date'] = pd.to_datetime(tree_df['date']).dt.strftime('%Y-%m-%d')#change date format into yyyy-mm-dd\n",
    "\n",
    "    #zipcode\n",
    "    tree_df['zipcode'] = tree_df['zipcode'].astype(int)\n",
    "    tree_df=tree_df.sort_values('date')\n",
    "\n",
    "    tree_df = gpd.GeoDataFrame(tree_df, geometry=gpd.points_from_xy(tree_df['longitude'], tree_df['latitude']))\n",
    "    tree_df.set_crs(epsg=4326, inplace=True)\n",
    "    return tree_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7164c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unit test\n",
    "download_and_clean_tree_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323e7af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_and_clean_zillow_data()-> DataFrame:\n",
    "    \"\"\"\n",
    "    Load and clean Zillow rent data from a CSV file, and transform it to a long format.\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: Cleaned and transformed data frame of Zillow rent data.\n",
    "    \"\"\"\n",
    "    # Load the CSV data using Pandas\n",
    "    zillow_data_path = DATA_DIR / \"zillow_rent_data.csv\"\n",
    "    df = pd.read_csv(zillow_data_path)\n",
    "    \n",
    "    # Keep only necessary columns\n",
    "    columns_to_keep = ['RegionName', 'State', 'City', 'Metro', 'CountyName'] + [col for col in df.columns if '-' in col]\n",
    "    df_cleaned = df[columns_to_keep]\n",
    "    \n",
    "    # Remove rows with a significant number of missing values\n",
    "    df_cleaned = df_cleaned.dropna(thresh=len(df_cleaned.columns)/2, axis=0)\n",
    "\n",
    "    # Filter for rows where the State is 'NY'\n",
    "    df_cleaned = df_cleaned[df_cleaned['State'] == 'NY']\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    df_cleaned = df_cleaned.rename(columns={'RegionName': 'ZipCode'})\n",
    "\n",
    "    # Convert the data from wide format to long format\n",
    "    # Melt the DataFrame to have Date and Rent as separate columns\n",
    "    date_columns = [col for col in df_cleaned.columns if '-' in col]\n",
    "    df_cleaned = df_cleaned.melt(id_vars=['ZipCode', 'State', 'City', 'Metro', 'CountyName'],\n",
    "                                     value_vars=date_columns,\n",
    "                                     var_name='Date',\n",
    "                                     value_name='Rent')\n",
    "    df_cleaned['ZipCode']=df_cleaned['ZipCode'].astype(float).astype(int)\n",
    "    # Normalize column names\n",
    "    df_cleaned.columns = [column_name.lower().replace(' ', '_') for column_name in df_cleaned.columns]\n",
    "    \n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e15398a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unit test\n",
    "load_and_clean_zillow_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345ebc2c-14f1-490c-9857-11f1e332e3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data():\n",
    "    \"\"\"\n",
    "    Load all necessary data for the project.\n",
    "\n",
    "    Returns:\n",
    "    Tuple containing:\n",
    "        - GeoDataFrame of cleaned NYC zipcode data.\n",
    "        - GeoDataFrame of cleaned NYC 311 data.\n",
    "        - GeoDataFrame of cleaned tree data.\n",
    "        - DataFrame of cleaned Zillow rent data.\n",
    "    \"\"\"\n",
    "    geodf_zipcode_data = load_and_clean_zipcodes(ZIPCODE_DATA_FILE)\n",
    "    geodf_311_data = download_and_clean_311_data()\n",
    "    geodf_tree_data = download_and_clean_tree_data()\n",
    "    df_zillow_data = load_and_clean_zillow_data()\n",
    "    return (\n",
    "        geodf_zipcode_data,\n",
    "        geodf_311_data,\n",
    "        geodf_tree_data,\n",
    "        df_zillow_data\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2768bc8-4130-4298-be28-13d4b250a666",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_zipcode_data, geodf_311_data, geodf_tree_data, df_zillow_data = load_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ad8bbc-bf91-457e-97db-a945fabeee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show basic info about each dataframe\n",
    "geodf_zipcode_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec68f4be-f365-46c1-91a1-ab75deb75ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first 5 entries about each dataframe\n",
    "geodf_zipcode_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a803b68-2f07-44b8-8b24-d4f16c9e03fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_311_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14705df9-ea77-4d57-ac8e-1845f80a216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_311_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6006cd2-3a00-4660-8d2a-a660b9bfd91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_tree_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f880ef-c5fc-4159-8174-21ccd44f492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_tree_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59724f74-5f1e-435c-b843-f381a875dd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zillow_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29ae5d9-9768-4590-a2f2-dd63b07dd712",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zillow_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e685942c-26dc-40db-84c2-a71aa3340806",
   "metadata": {},
   "source": [
    "## Part 2: Storing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527a251c-f337-4b24-bb41-96ee4621a9bd",
   "metadata": {},
   "source": [
    "### Creating Tables\n",
    "\n",
    "\n",
    "These are just a couple of options to creating your tables; you can use one or the other, a different method, or a combination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232a2d89-b276-4d44-a0ef-3631eb686e84",
   "metadata": {},
   "source": [
    "#### Option 2: SQLAlchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41c42e1-4ad4-4c43-a2ba-1dbcac1de557",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base = declarative_base()\n",
    "\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Float, Date, MetaData, Table\n",
    "from geoalchemy2 import Geometry\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "\n",
    "class ZipcodeArea(Base):\n",
    "    __tablename__ = 'zipcode_areas'  # Replace with your actual table name\n",
    "    # Assuming 'zipcode' is a unique identifier for each row\n",
    "    zipcode = Column(Integer, primary_key=True)\n",
    "    city = Column(String)\n",
    "    population = Column(Integer)\n",
    "    area = Column(Float)\n",
    "    county = Column(String)\n",
    "    geometry = Column(Geometry('POLYGON', srid=4326))  # Adjust the geometry type if needed\n",
    "\n",
    "class NYC311Complaints(Base):\n",
    "    __tablename__ = 'nyc311_complaints'\n",
    "    id_nyc = Column(Integer, primary_key=True)\n",
    "    date = Column(Date)\n",
    "    complaint_type = Column(String)\n",
    "    zipcode = Column(Integer)\n",
    "    latitude = Column(Float)\n",
    "    longitude = Column(Float)\n",
    "    geometry = Column(Geometry(geometry_type='POINT', srid=4326))\n",
    "\n",
    "class Tree(Base):\n",
    "    __tablename__ = 'trees'\n",
    "    tree_id = Column(Integer, primary_key=True)\n",
    "    date = Column(Date)\n",
    "    status = Column(String)\n",
    "    zipcode = Column(Integer)\n",
    "    health = Column(String)\n",
    "    spc_common = Column(String)\n",
    "    latitude = Column(Float)\n",
    "    longitude = Column(Float)\n",
    "    geometry = Column(Geometry(geometry_type='POINT', srid=4326))\n",
    "\n",
    "class Rent(Base):\n",
    "    __tablename__ = 'rents'\n",
    "    id=Column(Integer, primary_key=True)\n",
    "    zipcode = Column(Integer)\n",
    "    state = Column(String)\n",
    "    city = Column(String)\n",
    "    metro = Column(String)\n",
    "    countyname = Column(String)\n",
    "    date = Column(Date)\n",
    "    rent = Column(Float)\n",
    "\n",
    "engine = create_engine(DB_URL)\n",
    "Base.metadata.create_all(engine)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579a286b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unit test\n",
    "class TestZipcodeArea(unittest.TestCase):\n",
    "\n",
    "    def test_initialization(self):\n",
    "        zipcode_area = ZipcodeArea(\n",
    "            zipcode=12345,\n",
    "            city='New York',\n",
    "            population=8000000,\n",
    "            area=300.5,\n",
    "            county='New York County',\n",
    "            geometry='POLYGON'  # Simplified for the example\n",
    "        )\n",
    "        self.assertEqual(zipcode_area.zipcode, 12345)\n",
    "        self.assertEqual(zipcode_area.city, 'New York')\n",
    "        complaint = NYC311Complaints(\n",
    "                id_nyc=1,\n",
    "                date=date(2021, 1, 1),\n",
    "                complaint_type='Noise',\n",
    "                zipcode=10001,\n",
    "                latitude=40.7128,\n",
    "                longitude=-74.0060\n",
    "            )\n",
    "        self.assertEqual(complaint.id_nyc, 1)\n",
    "        self.assertEqual(complaint.complaint_type, 'Noise')\n",
    "        tree = Tree(\n",
    "                tree_id=1,\n",
    "                date=date.today(),\n",
    "                status='Good',\n",
    "                zipcode=10001,\n",
    "                health='Healthy',\n",
    "                spc_common='Oak',\n",
    "                latitude=40.7128,\n",
    "                longitude=-74.0060\n",
    "            )\n",
    "        self.assertEqual(tree.tree_id, 1)\n",
    "        self.assertEqual(tree.status, 'Good')\n",
    "        self.assertEqual(tree.health, 'Healthy')\n",
    "        rents = Rent(\n",
    "            id=1,\n",
    "            zipcode=10001,\n",
    "            state='NY',\n",
    "            city='New York',\n",
    "            metro='New York Metro',\n",
    "            countyname='New York County',\n",
    "            date=date.today(),\n",
    "            rent=2000.00\n",
    "        )\n",
    "        self.assertEqual(rents.city, 'New York')\n",
    "        self.assertEqual(rents.rent, 2000.00)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e88a50c-9528-4a5c-9a52-b96781ee8985",
   "metadata": {},
   "source": [
    "### Add Data to Database\n",
    "\n",
    "These are just a couple of options to write data to your tables; you can use one or the other, a different method, or a combination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9207cec5",
   "metadata": {},
   "source": [
    "Add ZipCode Data to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c50667",
   "metadata": {},
   "outputs": [],
   "source": [
    "Session = db.orm.sessionmaker(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6126be5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from shapely import wkt\n",
    "\n",
    "geodf_zipcode_data['geometry'] = geodf_zipcode_data['geometry'].apply(lambda geom: geom.wkt)\n",
    "for index, row in geodf_zipcode_data.iterrows():\n",
    "    insert_stmt = insert(ZipcodeArea).values(\n",
    "        zipcode=row['zipcode'],\n",
    "        city=row['city'],\n",
    "        population=row['population'],\n",
    "        area=row['area'],\n",
    "        county=row['county'],\n",
    "        geometry=row['geometry']\n",
    "    )\n",
    "    on_conflict_stmt = insert_stmt.on_conflict_do_update(\n",
    "        index_elements=['zipcode'],  # Unique constraint or column(s) causing conflict\n",
    "        set_=dict(\n",
    "            city=row['city'],\n",
    "            population=row['population'],\n",
    "            area=row['area'],\n",
    "            county=row['county'],\n",
    "            geometry=row['geometry']\n",
    "        )\n",
    "    )\n",
    "    session.execute(on_conflict_stmt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc0d934",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f6e404",
   "metadata": {},
   "source": [
    "Add NYC 311 Complaint Data to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dce0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.dialects.postgresql import insert\n",
    "# Convert geometry column to WKT format\n",
    "geodf_311_data['geometry'] = geodf_311_data['geometry'].apply(lambda geom: geom.wkt)\n",
    "\n",
    "def insert_batch(session, model, data, batch_size=200000):\n",
    "    \"\"\"\n",
    "    Inserts data in batches to the database.\n",
    "\n",
    "    Args:\n",
    "    session (Session): The SQLAlchemy session for database operations.\n",
    "    model (Type[Base]): The SQLAlchemy model class representing the database table.\n",
    "    data (DataFrame): The DataFrame containing data to be inserted.\n",
    "    batch_size (int): The size of each batch for insertion.\n",
    "    \"\"\"\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        batch = data.iloc[i:i+batch_size].to_dict(orient='records')\n",
    "\n",
    "        for record in batch:\n",
    "            stmt = insert(model).values(record)\n",
    "            do_nothing_stmt = stmt.on_conflict_do_nothing(index_elements=['id_NYC311'])\n",
    "            session.execute(do_nothing_stmt)\n",
    "\n",
    "        session.commit()\n",
    "\n",
    "# Insert data in batches\n",
    "insert_batch(session, NYC311Complaints, geodf_311_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d792f6eb",
   "metadata": {},
   "source": [
    "Add Tree Data to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77174d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_tree_data['geometry'] = geodf_tree_data['geometry'].apply(lambda geom: geom.wkt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba74275",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "geodf_tree_data['geometry'] = geodf_tree_data['geometry'].apply(lambda geom: geom.wkt)\n",
    "\n",
    "for index, row in geodf_tree_data.iterrows():\n",
    "    # Create a TreeData object for each row\n",
    "    tree = Tree(\n",
    "        tree_id=row['tree_id'],\n",
    "        date=row['date'],\n",
    "        status=row['status'],\n",
    "        zipcode=row['zipcode'],\n",
    "        health=row['health'],\n",
    "        spc_common=row['spc_common'],\n",
    "        latitude=row['latitude'],\n",
    "        longitude=row['longitude'],\n",
    "        geometry=row['geometry']\n",
    "    )\n",
    "    # Add each TreeData object to the session\n",
    "    session.add(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea33daf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a340ea",
   "metadata": {},
   "source": [
    "Add Zillow Rent Data to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5181fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each row in the DataFrame for Zillow rent data\n",
    "for index, row in df_zillow_data.iterrows():\n",
    "    # Create a ZillowRent object for each row (assuming ZillowRent is the model class)\n",
    "    rent = Rent(\n",
    "        zipcode=row['zipcode'],\n",
    "        state=row['state'],\n",
    "        city=row['city'],\n",
    "        metro=row['metro'],\n",
    "        countyname=row['countyname'],\n",
    "        date=row['date'],\n",
    "        rent=row['rent']\n",
    "    )\n",
    "    # Add each ZillowRent object to the session\n",
    "    session.add(rent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e454a2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commit the session to save all added objects to the database\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb63b553-0c64-4da8-9fc7-41555d89d853",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac7e12b-e251-4f08-8dc5-601db30c2089",
   "metadata": {},
   "source": [
    "### Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2adbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the directory where query files will be saved\n",
    "# Creates the directory if it does not exist\n",
    "QUERY_DIR = pathlib.Path(\"queries\")\n",
    "QUERY_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Define the SQL query for Query 1\n",
    "# This query finds the number of 311 complaints per zip code \n",
    "# between 2022-10-01 and 2023-09-30 and orders them in descending order\n",
    "QUERY_1 = \"\"\"\n",
    "SELECT zipcode, COUNT(*) AS complaint_count\n",
    "FROM nyc311_complaints\n",
    "WHERE date BETWEEN '2022-10-01' AND '2023-09-30'\n",
    "GROUP BY zipcode\n",
    "ORDER BY complaint_count DESC;\n",
    "\"\"\"\n",
    "\n",
    "# Function to write the SQL query to a file\n",
    "def write_query_to_file(query, outfile):\n",
    "    \"\"\"\n",
    "    Writes a SQL query to a file.\n",
    "\n",
    "    Args:\n",
    "    query (str): The SQL query string.\n",
    "    outfile (pathlib.Path): The file path where the query will be saved.\n",
    "    \"\"\"\n",
    "    with open(outfile, 'w') as file:\n",
    "        file.write(query)\n",
    "\n",
    "# File path for saving the query\n",
    "QUERY_1_FILENAME = QUERY_DIR / \"complaints_per_zipcode.sql\"\n",
    "\n",
    "# Execute the query and print the results\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(QUERY_1))\n",
    "    for row in result:\n",
    "        print(row)\n",
    "\n",
    "# Write the query to a file\n",
    "write_query_to_file(QUERY_1, QUERY_1_FILENAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f63b95f",
   "metadata": {},
   "source": [
    "### Query 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682b9035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 2: Finding the top 10 zip codes with the most trees\n",
    "# This query aims to identify which 10 zip codes have the highest number of trees\n",
    "\n",
    "QUERY_2 = \"\"\"\n",
    "SELECT zipcode, COUNT(*) AS tree_count\n",
    "FROM trees\n",
    "GROUP BY zipcode\n",
    "ORDER BY tree_count DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "# File path for saving the query\n",
    "QUERY_2_FILENAME = QUERY_DIR / \"top_10_zipcodes_by_trees.sql\"\n",
    "\n",
    "# Execute the query and print the results\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(QUERY_2))\n",
    "    for row in result:\n",
    "        print(row)\n",
    "\n",
    "# Write the query to a file\n",
    "write_query_to_file(QUERY_2, QUERY_2_FILENAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7e33e5",
   "metadata": {},
   "source": [
    "### Query 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11a0c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 3: Calculating average rent in the areas with the most trees for August 2023\n",
    "# This query identifies the average rent by zip code for the top 10 zip codes with the most trees, \n",
    "# specifically for the month of August 2023\n",
    "\n",
    "QUERY_3 = \"\"\"\n",
    "WITH TopTreeZipCodes AS (\n",
    "    SELECT r.zipcode\n",
    "    FROM trees\n",
    "    JOIN rents r ON trees.zipcode = r.zipcode\n",
    "    GROUP BY r.zipcode\n",
    "    ORDER BY COUNT(*) DESC\n",
    "    LIMIT 10\n",
    ")\n",
    "SELECT ttz.zipcode, ROUND(CAST(AVG(r.rent) AS numeric), 2) AS average_rent\n",
    "FROM TopTreeZipCodes ttz\n",
    "JOIN rents r ON ttz.zipcode = r.zipcode\n",
    "WHERE r.date BETWEEN '2023-08-01' AND '2023-08-31'\n",
    "GROUP BY ttz.zipcode\n",
    "ORDER BY COUNT(*) DESC;\n",
    "\"\"\"\n",
    "\n",
    "# File path for saving the query\n",
    "QUERY_3_FILENAME = QUERY_DIR / \"average_rent_in_green_areas.sql\"\n",
    "\n",
    "# Execute the query and print the results\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(QUERY_3))\n",
    "    for row in result:\n",
    "        print(row)\n",
    "\n",
    "# Write the query to a file\n",
    "write_query_to_file(QUERY_3, QUERY_3_FILENAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5c0bbb",
   "metadata": {},
   "source": [
    "### Query 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29adf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 4: Correlation between area's rent, tree count, and number of 311 complaints\n",
    "# This query finds the 5 zip codes with the lowest and highest average rent for January 2023,\n",
    "# along with the tree count and complaint count for each zip code\n",
    "\n",
    "QUERY_4 = \"\"\"\n",
    "WITH RentRanking AS (\n",
    "    SELECT zipcode, ROUND(CAST(AVG(r.rent) AS numeric), 2) AS average_rent,\n",
    "    RANK() OVER (ORDER BY AVG(rent)) AS rent_rank\n",
    "    FROM rents r\n",
    "    WHERE date BETWEEN '2023-01-01' AND '2023-01-31'\n",
    "    GROUP BY zipcode\n",
    "),\n",
    "MaxRank AS (\n",
    "    SELECT MAX(rent_rank) AS max_rank FROM RentRanking\n",
    ")\n",
    "SELECT rr.zipcode, rr.average_rent, \n",
    "       (SELECT COUNT(*) FROM trees WHERE zipcode = rr.zipcode) AS tree_count,\n",
    "       (SELECT COUNT(*) FROM nyc311_complaints WHERE zipcode = rr.zipcode AND date BETWEEN '2023-01-01' AND '2023-01-31') AS complaint_count\n",
    "FROM RentRanking rr, MaxRank\n",
    "WHERE rr.rent_rank <= 5 OR rr.rent_rank >= (MaxRank.max_rank - 4)\n",
    "ORDER BY rr.average_rent;\n",
    "\"\"\"\n",
    "\n",
    "# File path for saving the query\n",
    "QUERY_4_FILENAME = QUERY_DIR / \"rent_tree_complaint_correlation.sql\"\n",
    "\n",
    "# Execute the query and print the results\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(QUERY_4))\n",
    "    for row in result:\n",
    "        print(row)\n",
    "\n",
    "# Write the query to a file\n",
    "write_query_to_file(QUERY_4, QUERY_4_FILENAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd939d04",
   "metadata": {},
   "source": [
    "### Query 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eacaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 5: Identifying areas with the most greenery using spatial join\n",
    "# This query rewrites Query 2 to include a spatial join between the trees table and the zipcodes table\n",
    "# to determine which trees are located within the boundary of a zipcode\n",
    "\n",
    "QUERY_5 = \"\"\"\n",
    "WITH TreeCount AS (\n",
    "    SELECT z.zipcode, COUNT(t.tree_id) AS tree_count\n",
    "    FROM zipcode_areas z\n",
    "    JOIN trees t ON ST_Within(t.geometry, z.geometry)\n",
    "    GROUP BY z.zipcode\n",
    ")\n",
    "SELECT zipcode, tree_count\n",
    "FROM TreeCount\n",
    "ORDER BY tree_count DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "# File path for saving the query\n",
    "QUERY_5_FILENAME = QUERY_DIR / \"greenery_areas_with_spatial_join.sql\"\n",
    "\n",
    "# Execute the query and print the results\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(QUERY_5))\n",
    "    for row in result:\n",
    "        print(row)\n",
    "\n",
    "# Write the query to a file\n",
    "write_query_to_file(QUERY_5, QUERY_5_FILENAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9b5bed",
   "metadata": {},
   "source": [
    "### Query 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0abc857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 6: Finding trees within a ½ mile radius of a specific coordinate point\n",
    "# This query identifies which trees are within a ½ mile radius of the given latitude and longitude\n",
    "\n",
    "QUERY_6 = \"\"\"\n",
    "SELECT \n",
    "    tree_id, \n",
    "    spc_common AS species, \n",
    "    health, \n",
    "    status, \n",
    "    ST_AsText(geometry) AS geom\n",
    "FROM \n",
    "    trees\n",
    "WHERE \n",
    "    ST_DWithin(\n",
    "        geometry,\n",
    "        ST_SetSRID(ST_MakePoint(-73.96253174434912, 40.80737875669467), 4326),\n",
    "        0.5 * 1609.34 -- 0.5 miles in meters\n",
    "\n",
    "    );\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# File path for saving the query\n",
    "QUERY_6_FILENAME = QUERY_DIR / \"trees_nearby_coordinate.sql\"\n",
    "\n",
    "# Execute the query and print the results\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(QUERY_6))\n",
    "    for row in result:\n",
    "        print(row)\n",
    "\n",
    "# Write the query to a file\n",
    "write_query_to_file(QUERY_6, QUERY_6_FILENAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75223ce5-6ab5-4613-b6af-fa8e33bcc7d5",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21fcfed-ddbb-4908-a60e-ed7cbc6d5b00",
   "metadata": {},
   "source": [
    "### Visualization 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5065ba",
   "metadata": {},
   "source": [
    "First, find the top 3 complaint types for October 1st, 2022 to September 30th, 2023 (inclusive). \n",
    "\n",
    "Then, create an appropriate visualization for the number of complaints per day over $timeframe for those complaint types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed80755f-d1e1-4e53-8ef8-f5295c59a3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_1():\n",
    "    # Query your database for the data needed.\n",
    "    \"\"\"\n",
    "    Queries the database for data needed for visual 1 and returns it as a DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing the queried data.\n",
    "    \"\"\"\n",
    "    query=\"\"\"\n",
    "WITH TopComplaints AS (\n",
    "    SELECT complaint_type\n",
    "    FROM nyc311_complaints\n",
    "    WHERE date BETWEEN '2022-10-01' AND '2023-09-30'\n",
    "    GROUP BY complaint_type\n",
    "    ORDER BY COUNT(*) DESC\n",
    "    LIMIT 3\n",
    ")\n",
    "SELECT n.date, tc.complaint_type, COUNT(*) AS daily_complaints\n",
    "FROM TopComplaints tc\n",
    "JOIN nyc311_complaints n ON tc.complaint_type = n.complaint_type\n",
    "WHERE n.date BETWEEN '2022-10-01' AND '2023-09-30'\n",
    "GROUP BY n.date, tc.complaint_type\n",
    "ORDER BY n.date, daily_complaints DESC;\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "    # You can put the data queried into a pandas/geopandas dataframe, if you wish\n",
    "    df = pd.read_sql_query(query, engine)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e9a771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib\n",
    "matplotlib.rcParams['animation.embed_limit'] = 300\n",
    "\n",
    "\n",
    "def plot_visual_1(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Plots a line chart showing daily complaints for the top 3 complaint types.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): The DataFrame containing the complaint data.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "    top_types = df['complaint_type'].value_counts().nlargest(3).index\n",
    "    df_top = df[df['complaint_type'].isin(top_types)]\n",
    "\n",
    "    # Create a dummy plot to initialize the legend correctly\n",
    "    for ctype in top_types:\n",
    "        ax.plot([], [], label=ctype)\n",
    "\n",
    "    def animate(i):\n",
    "        ax.clear()\n",
    "        sns.lineplot(data=df_top.iloc[:i], x='date', y='daily_complaints', hue='complaint_type', ax=ax)\n",
    "        plt.title('Daily Complaints for Top 3 Complaint Types (Oct 1, 2022 - Sep 30, 2023)')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Number of Complaints')\n",
    "        plt.grid(True)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "\n",
    "    ax.legend(title='Complaint Types')  # Set the legend\n",
    "    anim =animation.FuncAnimation(fig, animate, frames=len(df_top), interval=200)\n",
    "    return HTML(anim.to_jshtml())#animation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a2632a-b516-4a6e-8b67-97116ab6fce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization1_dataframe = get_data_for_visual_1()\n",
    "plot_visual_1(visualization1_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb89c90",
   "metadata": {},
   "source": [
    "### Visualization 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f282295d",
   "metadata": {},
   "source": [
    "Create a visualization that shows the number of complaints by complaint type for the top 10 complaints in zip code 10027 for October 1st, 2018 to September 30th, 2023 (inclusive). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1251942c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_visual_2(df)-> None :\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    sns.barplot(data=df, x='complaint_type', y='complaint_count')\n",
    "    plt.title('Top 10 Complaint Types in Zip Code 10027 (Oct 1, 2018 - Sep 30, 2023)')\n",
    "    plt.xlabel('Complaint Type')\n",
    "    plt.ylabel('Number of Complaints')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55b6907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_2()-> pd.DataFrame:\n",
    "    # SQL query to fetch top 10 complaint types in zip code 10027\n",
    "    \"\"\"\n",
    "    Plots a bar chart showing the count of different complaint types.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): The DataFrame containing the complaint data.\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    WITH TopComplaints AS (\n",
    "        SELECT complaint_type, COUNT(*) AS count\n",
    "        FROM nyc311_complaints\n",
    "        WHERE zipcode = 10027 AND date BETWEEN '2018-10-01' AND '2023-09-30'\n",
    "        GROUP BY complaint_type\n",
    "        ORDER BY count DESC\n",
    "        LIMIT 10\n",
    "    )\n",
    "    SELECT nyc311_complaints.complaint_type, COUNT(*) AS complaint_count\n",
    "    FROM TopComplaints\n",
    "    JOIN nyc311_complaints ON TopComplaints.complaint_type = nyc311_complaints.complaint_type\n",
    "    WHERE nyc311_complaints.zipcode = 10027 AND nyc311_complaints.date BETWEEN '2018-10-01' AND '2023-09-30'\n",
    "    GROUP BY nyc311_complaints.complaint_type\n",
    "    ORDER BY complaint_count DESC;\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute the query and return a DataFrame\n",
    "    df = pd.read_sql_query(query, engine)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01c2324",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization2_dataframe = get_data_for_visual_2()\n",
    "plot_visual_2(visualization2_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e407425e",
   "metadata": {},
   "source": [
    "### Visualization 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5534f3",
   "metadata": {},
   "source": [
    "Between January 1st, 2015 and September 30th, 2023 (inclusive), create a visualization using 2 subplots that share the x-axis where one subplot shows rent compared to the number of trees by zip code, and the other subplot shows rent compared to the number of complaints by zip code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e7e775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a more descriptive name for your function\n",
    "def plot_visual_3(df)-> None :\n",
    "    \"\"\"\n",
    "    Plots scatter plots to compare average rent with number of trees and number of complaints.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): The DataFrame containing the data for average rent, tree count, \n",
    "                       and complaint count.\n",
    "    \"\"\"\n",
    "    # Create a subgraph\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), sharex=True)\n",
    "\n",
    "    # Subgraph of rent versus number of trees\n",
    "    ax1.scatter(df['average_rent'], df['tree_count'], alpha=0.6)\n",
    "    ax1.set_ylabel('Number of Trees')\n",
    "    ax1.set_title('Average Rent vs Number of Trees by Zip Code')\n",
    "\n",
    "    # Subgraph of rent versus number of complaints\n",
    "    ax2.scatter(df['average_rent'], df['complaint_count'], alpha=0.6, color='orange')\n",
    "    ax2.set_xlabel('Average Rent ($)')\n",
    "    ax2.set_ylabel('Number of Complaints')\n",
    "    ax2.set_title('Average Rent vs Number of Complaints by Zip Code')\n",
    "\n",
    "    # show chart\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfadb9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_3()-> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Queries the database for data needed for visual 3 and returns it as a DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing the queried data for rent, tree count, and complaint count.\n",
    "    \"\"\"\n",
    "    # Query your database for the data needed.\n",
    "    \n",
    "    query=\"\"\"\n",
    "WITH RentData AS (\n",
    "        SELECT zipcode, AVG(rent) AS average_rent\n",
    "        FROM rents\n",
    "        WHERE date BETWEEN '2015-01-01' AND '2023-09-30'\n",
    "        GROUP BY zipcode\n",
    "    ),\n",
    "    TreeData AS (\n",
    "        SELECT zipcode, COUNT(*) AS tree_count\n",
    "        FROM trees\n",
    "        GROUP BY zipcode\n",
    "    ),\n",
    "    ComplaintData AS (\n",
    "        SELECT zipcode, COUNT(*) AS complaint_count\n",
    "        FROM nyc311_complaints\n",
    "        WHERE date BETWEEN '2015-01-01' AND '2023-09-30'\n",
    "        GROUP BY zipcode\n",
    "    )\n",
    "    SELECT r.zipcode, r.average_rent, t.tree_count, c.complaint_count\n",
    "    FROM RentData r\n",
    "    LEFT JOIN TreeData t ON r.zipcode = t.zipcode\n",
    "    LEFT JOIN ComplaintData c ON r.zipcode = c.zipcode;\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_sql_query(query, engine)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27f4e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization3_dataframe = get_data_for_visual_3()\n",
    "plot_visual_3(visualization3_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399cf5d0",
   "metadata": {},
   "source": [
    "### Visualization 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b386fc",
   "metadata": {},
   "source": [
    "Create a boxplot, where the x-axis is average rent in September 2023, separated into $1000 bins (i.e. $0-1000, $1001-2000, etc), and the y-axis is the number of 311 complaints observed in each zip code between October 1, 2022 (inclusive) to September 30, 2023 (inclusive).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9538451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_visual_4(df)-> None:\n",
    "    \"\"\"\n",
    "    Plots a boxplot showing the number of 311 complaints by different rent bins.\n",
    "\n",
    "    This function takes a DataFrame with rent bins and complaint counts and plots a boxplot\n",
    "    to visualize the distribution of 311 complaints across different rent levels.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing the rent bin and complaint count data.\n",
    "    \"\"\"\n",
    "    # Create the boxplot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(x='rent_bin', y='complaint_count', data=df)\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.title('Boxplot of 311 Complaints by Rent Bins (Sep 2023)')\n",
    "    plt.xlabel('Average Rent Bins ($1000 increments)')\n",
    "    plt.ylabel('Number of 311 Complaints')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa14f1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_4()-> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Plots a boxplot showing the number of 311 complaints by different rent bins.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): The DataFrame containing the rent bin and complaint count data.\n",
    "    \"\"\"\n",
    "    # Define SQL query to fetch required data\n",
    "    query = \"\"\"\n",
    "    WITH RentBins AS (\n",
    "        SELECT zipcode, \n",
    "               AVG(rent) AS average_rent,\n",
    "               WIDTH_BUCKET(AVG(rent), 0, 10000, 10) AS rent_bin\n",
    "        FROM rents\n",
    "        WHERE date BETWEEN '2023-09-01' AND '2023-09-30'\n",
    "        GROUP BY zipcode\n",
    "    ),\n",
    "    ComplaintsCount AS (\n",
    "        SELECT zipcode, \n",
    "               COUNT(*) AS complaint_count\n",
    "        FROM nyc311_complaints\n",
    "        WHERE date BETWEEN '2022-10-01' AND '2023-09-30'\n",
    "        GROUP BY zipcode\n",
    "    )\n",
    "    SELECT R.zipcode, \n",
    "           R.rent_bin, \n",
    "           R.average_rent, \n",
    "           C.complaint_count\n",
    "    FROM RentBins R\n",
    "    JOIN ComplaintsCount C ON R.zipcode = C.zipcode\n",
    "    ORDER BY R.rent_bin;\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute the query and return a DataFrame\n",
    "    df = pd.read_sql_query(query, engine)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9be177",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization4_dataframe = get_data_for_visual_4()\n",
    "plot_visual_4(visualization4_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c240bb",
   "metadata": {},
   "source": [
    "### Visualization 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089b47b4",
   "metadata": {},
   "source": [
    "Create a geospatial plot of the coordinates of reported 311 incidents that happened between January 1st, 2023 and September 30th, 2023 (inclusive) within a 1 kilometer radius of the same coordinate from Query 6 in Part 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabcc592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_visual_5(df)-> None:\n",
    "    \"\"\"\n",
    "    Plots a geospatial map showing recent 311 incidents in a specific area.\n",
    "\n",
    "    Args:\n",
    "    df (gpd.GeoDataFrame): The GeoDataFrame containing the geospatial data for plotting.\n",
    "    \"\"\"\n",
    "    # Create a geospatial map\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    df.plot(ax=ax, marker='o', color='blue', markersize=5)\n",
    "    \n",
    "    # Center point (for visualization center)\n",
    "    center_point = Point(-73.96253174434912, 40.80737875669467)\n",
    "    plt.scatter([center_point.x], [center_point.y], color='red')  # 红点代表中心点\n",
    "\n",
    "    # Set the chart title and label\n",
    "    plt.title('Recent 311 Incidents in the Immediate Area (Jan 1, 2023 - Sep 30, 2023)')\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "\n",
    "    # Show charts\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ade5185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_5()-> gpd.GeoDataFrame:\n",
    "     \"\"\"\n",
    "    Query and return geospatial data for NYC 311 complaints within a 1km radius of a specified point.\n",
    "\n",
    "    This function retrieves latitude and longitude data for NYC 311 complaints that are within a 1000-meter radius\n",
    "    of a given geographical point (latitude 40.80737875669467, longitude -73.96253174434912). \n",
    "    The data is filtered to include complaints registered between 2023-01-01 and 2023-09-30.\n",
    "\n",
    "    Args:\n",
    "        engine (Engine): A SQLAlchemy Engine object used to execute the database query.\n",
    "\n",
    "    Returns:\n",
    "        gpd.GeoDataFrame: A GeoDataFrame containing the queried data with geographical coordinates.\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    SELECT latitude, longitude\n",
    "FROM nyc311_complaints\n",
    "WHERE ST_DWithin(\n",
    "    geography(ST_MakePoint(longitude, latitude)),\n",
    "    geography(ST_MakePoint(-73.96253174434912, 40.80737875669467)), \n",
    "    1000 -- distance in meters\n",
    ")\n",
    "AND date BETWEEN '2023-01-01' AND '2023-09-30';\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    df_query_result = pd.read_sql_query(query, engine)\n",
    "    df = gpd.GeoDataFrame(\n",
    "        df_query_result,\n",
    "        geometry=gpd.points_from_xy(df_query_result.longitude, df_query_result.latitude)\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d1b7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization5_dataframe = get_data_for_visual_5()\n",
    "plot_visual_5(visualization5_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932e1aa4",
   "metadata": {},
   "source": [
    "### Visualization 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16812620",
   "metadata": {},
   "source": [
    "Create a geospatial plot of two sets of data: the coordinates of trees in NYC, and the coordinates of \"New Tree Request\" 311 complaint types that were made from October 1st, 2018 to September 30th, 2023 (inclusive). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42283858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_6()-> Tuple[gpd.GeoDataFrame, gpd.GeoDataFrame]:\n",
    "    \"\"\"\n",
    "    Retrieve geospatial data for trees and new tree requests in NYC.\n",
    "\n",
    "    This function performs two queries:\n",
    "    1. It retrieves latitude and longitude data for all trees in NYC from the 'trees' table.\n",
    "    2. It retrieves latitude and longitude data for 'New Tree Request' complaints registered \n",
    "       between 2018-10-01 and 2023-09-30 from the 'nyc311_complaints' table.\n",
    "\n",
    "    Args:\n",
    "        engine (Engine): A SQLAlchemy Engine object used to execute the database queries.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[gpd.GeoDataFrame, gpd.GeoDataFrame]: \n",
    "            - A GeoDataFrame containing the latitude and longitude of trees in NYC.\n",
    "            - A GeoDataFrame containing the latitude and longitude of new tree requests in NYC.\n",
    "    \"\"\"\n",
    "    query_trees = \"\"\"\n",
    "    SELECT latitude, longitude\n",
    "    FROM trees;\n",
    "    \"\"\"\n",
    "\n",
    "    query_new_tree_requests = \"\"\"\n",
    "    SELECT latitude, longitude\n",
    "    FROM nyc311_complaints\n",
    "    WHERE complaint_type = 'New Tree Request'\n",
    "    AND date BETWEEN '2018-10-01' AND '2023-09-30';\n",
    "    \"\"\"\n",
    "\n",
    "    df_trees = gpd.GeoDataFrame(\n",
    "        pd.read_sql_query(query_trees, engine),\n",
    "        geometry=gpd.points_from_xy(pd.read_sql_query(query_trees, engine).longitude, pd.read_sql_query(query_trees, engine).latitude)\n",
    "    )\n",
    "    df_new_tree_requests = gpd.GeoDataFrame(\n",
    "        pd.read_sql_query(query_new_tree_requests, engine),\n",
    "        geometry=gpd.points_from_xy(pd.read_sql_query(query_new_tree_requests, engine).longitude, pd.read_sql_query(query_new_tree_requests, engine).latitude)\n",
    "    )\n",
    "\n",
    "    return df_trees, df_new_tree_requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155777ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_visual_6(df_trees, df_new_tree_requests)-> None:\n",
    "    \"\"\"\n",
    "    Plot a geospatial chart showing locations of existing trees and new tree requests in NYC.\n",
    "\n",
    "    This function takes two GeoDataFrames: one representing the location of existing trees,\n",
    "    and the other representing new tree requests. It plots these locations on a map with\n",
    "    distinct markers and colors for easy differentiation.\n",
    "\n",
    "    Args:\n",
    "        df_trees (gpd.GeoDataFrame): A GeoDataFrame containing the latitude and longitude of trees in NYC.\n",
    "        df_new_tree_requests (gpd.GeoDataFrame): A GeoDataFrame containing the latitude and longitude of new tree requests in NYC.\n",
    "\n",
    "    Returns:\n",
    "        None: This function does not return anything but displays a matplotlib plot.\n",
    "    \"\"\"    \n",
    "    # Create a geospatial chart\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "    #Draw the new tree request location on the map\n",
    "    df_new_tree_requests.plot(ax=ax, markersize=5, color='red', label='New Tree Requests')\n",
    "    \n",
    "    # Plot the tree position on the map\n",
    "    df_trees.plot(ax=ax, markersize=5, color='green', label='Trees')\n",
    "\n",
    "    # Customize the chart\n",
    "    plt.title('Trees and New Tree Requests in NYC')\n",
    "    plt.legend()\n",
    "\n",
    "    # show chart\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e00e0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trees, df_new_tree_requests = get_data_for_visual_6()\n",
    "plot_visual_6(df_trees, df_new_tree_requests)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
