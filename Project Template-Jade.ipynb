{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4c5a136-e872-4846-9965-9ddc5251a0b3",
   "metadata": {},
   "source": [
    "# NYC Apartment Search\n",
    "\n",
    "_[Project prompt](https://docs.google.com/document/d/1BYVyFBDcTywdUlanH0ysfOrNWPgl7UkqXA7NeewTzxA/edit#heading=h.bpxu7uvknnbk)_\n",
    "\n",
    "_This scaffolding notebook may be used to help setup your final project. It's **totally optional** whether you make use of this or not._\n",
    "\n",
    "_If you do use this notebook, everything provided is optional as well - you may remove or add code as you wish._\n",
    "\n",
    "_**All code below should be consider \"pseudo-code\" - not functional by itself, and only an idea of a possible approach.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf11fa0-4684-4f5e-8048-0f4cc5f4f243",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f675d4b-794e-407c-aac9-b85c4a3975d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All import statements needed for the project, for example:\n",
    "\n",
    "import json\n",
    "import pathlib\n",
    "from requests.exceptions import ReadTimeout\n",
    "import time\n",
    "import geoalchemy2 as gdb\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import shapely\n",
    "import sqlalchemy as db\n",
    "from sodapy import Socrata\n",
    "import glob\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine,text\n",
    "\n",
    "from sqlalchemy.orm import declarative_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70a62277-51cf-48a2-81d2-9b2127088a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any constants you might need; some have been added for you\n",
    "\n",
    "# Where data files will be read from/written to - this should already exist\n",
    "DATA_DIR = pathlib.Path(\"data\")\n",
    "ZIPCODE_DATA_FILE = DATA_DIR / \"nyc_zipcodes.shp\"\n",
    "ZILLOW_DATA_FILE = DATA_DIR / \"zillow_rent_data.csv\"\n",
    "\n",
    "NYC_DATA_APP_TOKEN = \"xX3rCbSDM4vF0QEfgh09b2ZWW\"\n",
    "BASE_NYC_DATA_URL = \"https://data.cityofnewyork.us/\"\n",
    "NYC_DATA_311 = \"erm2-nwe9.geojson\"\n",
    "NYC_DATA_TREES = \"5rq2-4hqu.geojson\"\n",
    "\n",
    "DB_NAME = \"IEOR4501-XL\"\n",
    "\n",
    "DB_USER = \"postgres\"\n",
    "#DB_URL = f\"postgres+psycopg2://{DB_USER}@localhost/{DB_NAME}\"\n",
    "DB_URL = f\"postgresql://{DB_USER}@localhost/{DB_NAME}\"\n",
    "DB_SCHEMA_FILE = \"schema.sql\"\n",
    "\n",
    "QUERY_DIR = pathlib.Path(\"queries\")\n",
    "\n",
    "# directory where DB queries for Part 3 will be saved\n",
    "QUERY_DIR = pathlib.Path(\"queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd67cca9-ec72-44e3-83b8-b65f1ed5bb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the QUERY_DIRECTORY exists\n",
    "if not QUERY_DIR.exists():\n",
    "    QUERY_DIR.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52476a07-9bf2-4b7a-8cb7-93648bb4d303",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0f651ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloading data from small chunks\n",
    "def download_nyc_csv_data(year,starttime,endtime,url,filename):\n",
    "    filepath = f'{DATA_DIR}/{filename}_{year}.csv'\n",
    "    query=f\"\"\"\n",
    "    select * \n",
    "    where created_date between {starttime} \n",
    "    and {endtime}\n",
    "    \"\"\"\n",
    "\n",
    "    if not filename:\n",
    "        print(f\"Downloading {url} to {filename}...\")\n",
    "        client = Socrata( \"data.cityofnewyork.us\",\n",
    "                  \"xX3rCbSDM4vF0QEfgh09b2ZWW\",\n",
    "                  username=\"yirong263@gmail.com\",\n",
    "                  password=\"UTDYnmz*zn2u3g6\",\n",
    "                  timeout=60)\n",
    "        max_retries = 5\n",
    "        retry_wait = 10  # Initial wait time in seconds\n",
    "\n",
    "        while max_retries > 0:\n",
    "            try:    \n",
    "            # Set initial parameters for the SoQL query\n",
    "                limit = 1000000  # Example limit\n",
    "                offset = 0  # Start at the beginning\n",
    "                total_records = 100000000  # Example total number of records you wish to download\n",
    "                current_record = 0\n",
    "                while current_record < total_records:\n",
    "                    # Adjust the query to include the limit and offset\n",
    "                    results = client.get(f\"{url}\",query= query+ f\" limit {limit} offset {offset}\")\n",
    "                    \n",
    "                    # Convert to DataFrame and save to CSV\n",
    "                    df = pd.DataFrame.from_records(results)\n",
    "                    df.to_csv(f'{filepath}', index=False)\n",
    "                    \n",
    "                    # Update the offset and current_record count\n",
    "                    offset += limit\n",
    "                    current_record += len(results)\n",
    "\n",
    "                    # Optional: Print progress\n",
    "                    print(f'Downloaded {current_record} of {total_records}')\n",
    "                break\n",
    "            \n",
    "            except ReadTimeout:\n",
    "                # Wait before retrying\n",
    "                time.sleep(retry_wait)\n",
    "                # Reduce the number of retries left\n",
    "                max_retries -= 1\n",
    "                # Increase the wait time for the next retry\n",
    "                retry_wait *= 2\n",
    "        \n",
    "        print(f\"Done downloading {url} from {year}.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Reading from {filepath}...\")\n",
    "\n",
    "\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee245240-2fbb-45b8-9a92-4e2368f62c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_zipcodes(zipcode_datafile):\n",
    "    \"\"\"\n",
    "    Load and clean NYC zipcode data from a shapefile.\n",
    "    Args:\n",
    "    zipcode_datafile (str): The file path to the shapefile.\n",
    "    \n",
    "    Returns:\n",
    "    GeoDataFrame: Cleaned geospatial data frame of NYC zipcodes.\n",
    "    \"\"\"\n",
    "    # Load the shapefile using GeoPandas\n",
    "    gdf = gpd.read_file(zipcode_datafile)\n",
    "    \n",
    "    # Remove unnecessary columns from the dataframe\n",
    "    columns_to_drop = ['BLDGZIP', 'STATE', 'ST_FIPS', 'CTY_FIPS', 'URL', 'SHAPE_AREA', 'SHAPE_LEN']\n",
    "    gdf_cleaned = gdf.drop(columns=columns_to_drop)\n",
    "    gdf.drop_duplicates(subset='ZIPCODE', keep='first', inplace=True)\n",
    "    gdf.dropna(inplace=True)\n",
    "    gdf.drop_duplicates(inplace=True)\n",
    "    # Rename columns for clarity\n",
    "    gdf_cleaned = gdf_cleaned.rename(columns={'PO_NAME': 'City'})\n",
    "    # Set the coordinate reference system to EPSG 4326\n",
    "    gdf_cleaned = gdf_cleaned.to_crs(epsg=4326)\n",
    "    # Normalize column names\n",
    "    gdf_cleaned.columns = [column_name.lower().replace(' ', '_') for column_name in gdf_cleaned.columns]\n",
    "    gdf_cleaned['zipcode']=gdf_cleaned['zipcode'].astype(float).astype(int)\n",
    "    gdf_cleaned['population']=gdf_cleaned['population'].astype(float).astype(int)\n",
    "\n",
    "    return gdf_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eed2a5a9-1027-4c41-bbb5-039c32ce7e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_clean_311_data():\n",
    "    #data downloading\n",
    "    download_nyc_csv_data(2015,\"2015-01-01T00:00:00.000\",\"2015-12-31T23:59:59.999\",\"erm2-nwe9\",'nyc_311_data')\n",
    "    download_nyc_csv_data(2016,\"2016-01-01T00:00:00.000\",\"2016-12-31T23:59:59.999\",\"erm2-nwe9\",'nyc_311_data')\n",
    "    download_nyc_csv_data(2017,\"2017-01-01T00:00:00.000\",\"2017-12-31T23:59:59.999\",\"erm2-nwe9\",'nyc_311_data')\n",
    "    download_nyc_csv_data(2018,\"2018-01-01T00:00:00.000\",\"2018-12-31T23:59:59.999\",\"erm2-nwe9\",'nyc_311_data')\n",
    "    download_nyc_csv_data(2019,\"2019-01-01T00:00:00.000\",\"2019-12-31T23:59:59.999\",\"erm2-nwe9\",'nyc_311_data')\n",
    "    download_nyc_csv_data(2020,\"2020-01-01T00:00:00.000\",\"2020-12-31T23:59:59.999\",\"erm2-nwe9\",'nyc_311_data')\n",
    "    download_nyc_csv_data(2021,\"2021-01-01T00:00:00.000\",\"2021-12-31T23:59:59.999\",\"erm2-nwe9\",'nyc_311_data')\n",
    "    download_nyc_csv_data(2022,\"2022-01-01T00:00:00.000\",\"2022-12-31T23:59:59.999\",\"erm2-nwe9\",'nyc_311_data')\n",
    "    download_nyc_csv_data(2023,\"2023-01-01T00:00:00.000\",\"2015-09-30T23:59:59.999\",\"erm2-nwe9\",'nyc_311_data')\n",
    "\n",
    "    # After downloading all chunks\n",
    "    csv_files = glob.glob('data/nyc_311_data_*.csv')\n",
    "    # Remove unnecessary columns by keeping only the ones you need for each file\n",
    "    dfs=[]\n",
    "    for file in csv_files:\n",
    "        df=pd.read_csv(file)\n",
    "        columns_needed = ['unique_key', 'created_date', 'complaint_type','incident_zip','latitude', 'longitude']  # Replace with actual column names\n",
    "        df = df[columns_needed]\n",
    "        #eliminate duplicate\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        # Remove invalid data points\n",
    "        # This is highly dependent on the context of your data, but as an example:\n",
    "        df.dropna(inplace=True) \n",
    "        # Normalize column names\n",
    "        df.columns = [column_name.lower().replace(' ', '_') for column_name in df.columns]\n",
    "        dfs.append(df) # processed df and append to a list\n",
    "\n",
    "    # Concatenate all DataFrames into one\n",
    "    NYC311_df = pd.concat(dfs,ignore_index=True)\n",
    "    NYC311_df.drop_duplicates(inplace=True)# header duplicate elimination\n",
    "    NYC311_df = NYC311_df.drop_duplicates(subset=['unique_key'])\n",
    "    # Normalize Column Types\n",
    "\n",
    "    # unique_key \n",
    "    NYC311_df['unique_key'] = NYC311_df['unique_key'].astype(int)\n",
    "    # change name into 'id_NYC311'\n",
    "    NYC311_df.rename(columns={'unique_key': 'id_NYC311'}, inplace=True)\n",
    "\n",
    "    #incident zip\n",
    "    #rename from incident_zip to zipcode\n",
    "    NYC311_df.rename(columns={'incident_zip': 'zipcode'}, inplace=True)\n",
    "  \n",
    "    NYC311_df['zipcode']=NYC311_df['zipcode'].astype(float).astype(int)\n",
    "    NYC311_df = NYC311_df[NYC311_df['zipcode'].apply(lambda x: str(x).isdigit() and len(str(x)) == 5)] \n",
    "\n",
    "    #created_date\n",
    "    #rename \"date\"\n",
    "    NYC311_df.rename(columns={'created_date': 'date'}, inplace=True)\n",
    "    # sorting by date\n",
    "    NYC311_df = NYC311_df.sort_values(by='date')\n",
    "    #change date format into yyyy-mm-dd\n",
    "    NYC311_df['date'] = pd.to_datetime(NYC311_df['date']).dt.strftime('%Y-%m-%d')\n",
    "        \n",
    "    # Assuming df is your existing DataFrame with latitude and longitude columns\n",
    "    NYC311_df = gpd.GeoDataFrame(NYC311_df, geometry=gpd.points_from_xy(NYC311_df['longitude'], NYC311_df['latitude']))\n",
    "    NYC311_df.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "\n",
    "    #save the combined DataFrame to a new CSV file\n",
    "    # NYC311_df.to_csv('data/nyc_311_data.csv', index=False)\n",
    "    return NYC311_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39c4b1bc-c841-4b87-8301-1dc2cafeccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_clean_tree_data():\n",
    "    download_nyc_csv_data(2015,\"2015-01-01T00:00:00.000\",\"2015-12-31T23:59:59.999\",\"5rq2-4hqu\",'tree')\n",
    "    tree_df=pd.read_csv('data/tree_2015.csv')\n",
    "    # Remove unnecessary columns by keeping only the ones you need\n",
    "    columns_needed = ['created_at', 'tree_id', 'status','zipcode','health','spc_common', 'latitude', 'longitude']  # Replace with actual column names\n",
    "    tree_df = tree_df[columns_needed]\n",
    "\n",
    "    # Remove invalid data points\n",
    "    # This is highly dependent on the context of your data, but as an example:\n",
    "    tree_df.drop_duplicates(inplace=True)\n",
    "    tree_df.dropna(inplace=True)  \n",
    "\n",
    "    # Normalize column names\n",
    "    tree_df.columns = [column_name.lower().replace(' ', '_') for column_name in tree_df.columns]\n",
    "    #created_at\n",
    "    tree_df.rename(columns={'created_at': 'date'}, inplace=True)\n",
    "    tree_df['date'] = pd.to_datetime(tree_df['date']).dt.strftime('%Y-%m-%d')#change date format into yyyy-mm-dd\n",
    "\n",
    "    #zipcode\n",
    "    tree_df['zipcode'] = tree_df['zipcode'].astype(int)\n",
    "    tree_df=tree_df.sort_values('date')\n",
    "\n",
    "    tree_df = gpd.GeoDataFrame(tree_df, geometry=gpd.points_from_xy(tree_df['longitude'], tree_df['latitude']))\n",
    "    tree_df.set_crs(epsg=4326, inplace=True)\n",
    "    return tree_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323e7af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mport pandas as pd\n",
    "\n",
    "def load_and_clean_zillow_data():\n",
    "    \"\"\"\n",
    "    Load and clean Zillow rent data from a CSV file, and transform it to a long format.\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: Cleaned and transformed data frame of Zillow rent data.\n",
    "    \"\"\"\n",
    "    # Load the CSV data using Pandas\n",
    "    zillow_data_path = DATA_DIR / \"zillow_rent_data.csv\"\n",
    "    df = pd.read_csv(zillow_data_path)\n",
    "    \n",
    "    # Keep only necessary columns\n",
    "    columns_to_keep = ['RegionName', 'State', 'City', 'Metro', 'CountyName'] + [col for col in df.columns if '-' in col]\n",
    "    df_cleaned = df[columns_to_keep]\n",
    "    \n",
    "    # Remove rows with a significant number of missing values\n",
    "    df_cleaned = df_cleaned.dropna(thresh=len(df_cleaned.columns)/2, axis=0)\n",
    "\n",
    "    # Filter for rows where the State is 'NY'\n",
    "    df_cleaned = df_cleaned[df_cleaned['State'] == 'NY']\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    df_cleaned = df_cleaned.rename(columns={'RegionName': 'ZipCode'})\n",
    "\n",
    "    # Convert the data from wide format to long format\n",
    "    # Melt the DataFrame to have Date and Rent as separate columns\n",
    "    date_columns = [col for col in df_cleaned.columns if '-' in col]\n",
    "    df_cleaned = df_cleaned.melt(id_vars=['ZipCode', 'State', 'City', 'Metro', 'CountyName'],\n",
    "                                     value_vars=date_columns,\n",
    "                                     var_name='Date',\n",
    "                                     value_name='Rent')\n",
    "    df_cleaned['ZipCode']=df_cleaned['ZipCode'].astype(float).astype(int)\n",
    "    # Normalize column names\n",
    "    df_cleaned.columns = [column_name.lower().replace(' ', '_') for column_name in df_cleaned.columns]\n",
    "    \n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "345ebc2c-14f1-490c-9857-11f1e332e3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data():\n",
    "    geodf_zipcode_data = load_and_clean_zipcodes(ZIPCODE_DATA_FILE)\n",
    "    geodf_311_data = download_and_clean_311_data()\n",
    "    geodf_tree_data = download_and_clean_tree_data()\n",
    "    df_zillow_data = load_and_clean_zillow_data()\n",
    "    return (\n",
    "        geodf_zipcode_data,\n",
    "        geodf_311_data,\n",
    "        geodf_tree_data,\n",
    "        df_zillow_data\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f2768bc8-4130-4298-be28-13d4b250a666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from data/nyc_311_data_2015.csv...\n",
      "Reading from data/nyc_311_data_2016.csv...\n",
      "Reading from data/nyc_311_data_2017.csv...\n",
      "Reading from data/nyc_311_data_2018.csv...\n",
      "Reading from data/nyc_311_data_2019.csv...\n",
      "Reading from data/nyc_311_data_2020.csv...\n",
      "Reading from data/nyc_311_data_2021.csv...\n",
      "Reading from data/nyc_311_data_2022.csv...\n",
      "Reading from data/nyc_311_data_2023.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3q/9w4rbrs12tv6_t2_bscp34qm0000gn/T/ipykernel_99131/883424399.py:18: DtypeWarning: Columns (8,39,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv(file)\n",
      "/var/folders/3q/9w4rbrs12tv6_t2_bscp34qm0000gn/T/ipykernel_99131/883424399.py:18: DtypeWarning: Columns (8,38,39,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv(file)\n",
      "/var/folders/3q/9w4rbrs12tv6_t2_bscp34qm0000gn/T/ipykernel_99131/883424399.py:18: DtypeWarning: Columns (8,33,34,35,36,37,39,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv(file)\n",
      "/var/folders/3q/9w4rbrs12tv6_t2_bscp34qm0000gn/T/ipykernel_99131/883424399.py:18: DtypeWarning: Columns (8,34,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv(file)\n",
      "/var/folders/3q/9w4rbrs12tv6_t2_bscp34qm0000gn/T/ipykernel_99131/883424399.py:18: DtypeWarning: Columns (38,39,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv(file)\n",
      "/var/folders/3q/9w4rbrs12tv6_t2_bscp34qm0000gn/T/ipykernel_99131/883424399.py:18: DtypeWarning: Columns (39,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv(file)\n",
      "/var/folders/3q/9w4rbrs12tv6_t2_bscp34qm0000gn/T/ipykernel_99131/883424399.py:18: DtypeWarning: Columns (8,38,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv(file)\n",
      "/var/folders/3q/9w4rbrs12tv6_t2_bscp34qm0000gn/T/ipykernel_99131/883424399.py:18: DtypeWarning: Columns (8,39,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv(file)\n",
      "/var/folders/3q/9w4rbrs12tv6_t2_bscp34qm0000gn/T/ipykernel_99131/883424399.py:18: DtypeWarning: Columns (8,39,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from data/tree_2015.csv...\n"
     ]
    }
   ],
   "source": [
    "geodf_zipcode_data, geodf_311_data, geodf_tree_data, df_zillow_data = load_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23ad8bbc-bf91-457e-97db-a945fabeee29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 263 entries, 0 to 262\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   zipcode     263 non-null    int64   \n",
      " 1   city        263 non-null    object  \n",
      " 2   population  263 non-null    float64 \n",
      " 3   area        263 non-null    float64 \n",
      " 4   county      263 non-null    object  \n",
      " 5   geometry    263 non-null    geometry\n",
      "dtypes: float64(2), geometry(1), int64(1), object(2)\n",
      "memory usage: 12.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Show basic info about each dataframe\n",
    "geodf_zipcode_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec68f4be-f365-46c1-91a1-ab75deb75ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zipcode</th>\n",
       "      <th>city</th>\n",
       "      <th>population</th>\n",
       "      <th>area</th>\n",
       "      <th>county</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11436</td>\n",
       "      <td>Jamaica</td>\n",
       "      <td>18681.0</td>\n",
       "      <td>2.269930e+07</td>\n",
       "      <td>Queens</td>\n",
       "      <td>POLYGON ((-73.80585 40.68291, -73.80569 40.682...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11213</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>62426.0</td>\n",
       "      <td>2.963100e+07</td>\n",
       "      <td>Kings</td>\n",
       "      <td>POLYGON ((-73.93740 40.67973, -73.93487 40.679...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11212</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>83866.0</td>\n",
       "      <td>4.197210e+07</td>\n",
       "      <td>Kings</td>\n",
       "      <td>POLYGON ((-73.90294 40.67084, -73.90223 40.668...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11225</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>56527.0</td>\n",
       "      <td>2.369863e+07</td>\n",
       "      <td>Kings</td>\n",
       "      <td>POLYGON ((-73.95797 40.67066, -73.95576 40.670...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11218</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>72280.0</td>\n",
       "      <td>3.686880e+07</td>\n",
       "      <td>Kings</td>\n",
       "      <td>POLYGON ((-73.97208 40.65060, -73.97192 40.650...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   zipcode      city  population          area  county  \\\n",
       "0    11436   Jamaica     18681.0  2.269930e+07  Queens   \n",
       "1    11213  Brooklyn     62426.0  2.963100e+07   Kings   \n",
       "2    11212  Brooklyn     83866.0  4.197210e+07   Kings   \n",
       "3    11225  Brooklyn     56527.0  2.369863e+07   Kings   \n",
       "4    11218  Brooklyn     72280.0  3.686880e+07   Kings   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((-73.80585 40.68291, -73.80569 40.682...  \n",
       "1  POLYGON ((-73.93740 40.67973, -73.93487 40.679...  \n",
       "2  POLYGON ((-73.90294 40.67084, -73.90223 40.668...  \n",
       "3  POLYGON ((-73.95797 40.67066, -73.95576 40.670...  \n",
       "4  POLYGON ((-73.97208 40.65060, -73.97192 40.650...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show first 5 entries about each dataframe\n",
    "geodf_zipcode_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a803b68-2f07-44b8-8b24-d4f16c9e03fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "Int64Index: 23030426 entries, 291587 to 16420015\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Dtype   \n",
      "---  ------          -----   \n",
      " 0   id_NYC311       int64   \n",
      " 1   date            object  \n",
      " 2   complaint_type  object  \n",
      " 3   zipcode         int64   \n",
      " 4   latitude        float64 \n",
      " 5   longitude       float64 \n",
      " 6   geometry        geometry\n",
      "dtypes: float64(2), geometry(1), int64(2), object(2)\n",
      "memory usage: 1.4+ GB\n"
     ]
    }
   ],
   "source": [
    "geodf_311_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14705df9-ea77-4d57-ac8e-1845f80a216d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_NYC311</th>\n",
       "      <th>date</th>\n",
       "      <th>complaint_type</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>291587</th>\n",
       "      <td>29616011</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>HEAT/HOT WATER</td>\n",
       "      <td>11207</td>\n",
       "      <td>40.667093</td>\n",
       "      <td>-73.891719</td>\n",
       "      <td>POINT (-73.89172 40.66709)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291738</th>\n",
       "      <td>29615514</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>HEAT/HOT WATER</td>\n",
       "      <td>10034</td>\n",
       "      <td>40.868366</td>\n",
       "      <td>-73.916422</td>\n",
       "      <td>POINT (-73.91642 40.86837)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291739</th>\n",
       "      <td>29615513</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>HEAT/HOT WATER</td>\n",
       "      <td>11377</td>\n",
       "      <td>40.744999</td>\n",
       "      <td>-73.892968</td>\n",
       "      <td>POINT (-73.89297 40.74500)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291740</th>\n",
       "      <td>29615512</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>HEAT/HOT WATER</td>\n",
       "      <td>10472</td>\n",
       "      <td>40.833156</td>\n",
       "      <td>-73.870540</td>\n",
       "      <td>POINT (-73.87054 40.83316)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291741</th>\n",
       "      <td>29615511</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>HEAT/HOT WATER</td>\n",
       "      <td>10024</td>\n",
       "      <td>40.787862</td>\n",
       "      <td>-73.976899</td>\n",
       "      <td>POINT (-73.97690 40.78786)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_NYC311        date  complaint_type  zipcode   latitude  longitude  \\\n",
       "291587   29616011  2015-01-01  HEAT/HOT WATER    11207  40.667093 -73.891719   \n",
       "291738   29615514  2015-01-01  HEAT/HOT WATER    10034  40.868366 -73.916422   \n",
       "291739   29615513  2015-01-01  HEAT/HOT WATER    11377  40.744999 -73.892968   \n",
       "291740   29615512  2015-01-01  HEAT/HOT WATER    10472  40.833156 -73.870540   \n",
       "291741   29615511  2015-01-01  HEAT/HOT WATER    10024  40.787862 -73.976899   \n",
       "\n",
       "                          geometry  \n",
       "291587  POINT (-73.89172 40.66709)  \n",
       "291738  POINT (-73.91642 40.86837)  \n",
       "291739  POINT (-73.89297 40.74500)  \n",
       "291740  POINT (-73.87054 40.83316)  \n",
       "291741  POINT (-73.97690 40.78786)  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geodf_311_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6006cd2-3a00-4660-8d2a-a660b9bfd91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "Int64Index: 189969 entries, 13800 to 196344\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count   Dtype   \n",
      "---  ------      --------------   -----   \n",
      " 0   date        189969 non-null  object  \n",
      " 1   tree_id     189969 non-null  int64   \n",
      " 2   status      189969 non-null  object  \n",
      " 3   zipcode     189969 non-null  int64   \n",
      " 4   health      189969 non-null  object  \n",
      " 5   spc_common  189969 non-null  object  \n",
      " 6   latitude    189969 non-null  float64 \n",
      " 7   longitude   189969 non-null  float64 \n",
      " 8   geometry    189969 non-null  geometry\n",
      "dtypes: float64(2), geometry(1), int64(2), object(4)\n",
      "memory usage: 14.5+ MB\n"
     ]
    }
   ],
   "source": [
    "geodf_tree_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "07f880ef-c5fc-4159-8174-21ccd44f492d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tree_id</th>\n",
       "      <th>status</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>health</th>\n",
       "      <th>spc_common</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13800</th>\n",
       "      <td>2015-05-19</td>\n",
       "      <td>347</td>\n",
       "      <td>Alive</td>\n",
       "      <td>10459</td>\n",
       "      <td>Fair</td>\n",
       "      <td>American hornbeam</td>\n",
       "      <td>40.821445</td>\n",
       "      <td>-73.892916</td>\n",
       "      <td>POINT (-73.89292 40.82144)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45386</th>\n",
       "      <td>2015-05-19</td>\n",
       "      <td>317</td>\n",
       "      <td>Alive</td>\n",
       "      <td>10459</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Amur maackia</td>\n",
       "      <td>40.825308</td>\n",
       "      <td>-73.897495</td>\n",
       "      <td>POINT (-73.89750 40.82531)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>2015-05-19</td>\n",
       "      <td>306</td>\n",
       "      <td>Alive</td>\n",
       "      <td>10459</td>\n",
       "      <td>Good</td>\n",
       "      <td>Siberian elm</td>\n",
       "      <td>40.823933</td>\n",
       "      <td>-73.897177</td>\n",
       "      <td>POINT (-73.89718 40.82393)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22732</th>\n",
       "      <td>2015-05-19</td>\n",
       "      <td>9</td>\n",
       "      <td>Alive</td>\n",
       "      <td>10474</td>\n",
       "      <td>Poor</td>\n",
       "      <td>silver birch</td>\n",
       "      <td>40.814107</td>\n",
       "      <td>-73.889021</td>\n",
       "      <td>POINT (-73.88902 40.81411)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4301</th>\n",
       "      <td>2015-05-19</td>\n",
       "      <td>307</td>\n",
       "      <td>Alive</td>\n",
       "      <td>10459</td>\n",
       "      <td>Good</td>\n",
       "      <td>Siberian elm</td>\n",
       "      <td>40.824059</td>\n",
       "      <td>-73.897260</td>\n",
       "      <td>POINT (-73.89726 40.82406)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  tree_id status  zipcode health         spc_common  \\\n",
       "13800  2015-05-19      347  Alive    10459   Fair  American hornbeam   \n",
       "45386  2015-05-19      317  Alive    10459   Fair       Amur maackia   \n",
       "1890   2015-05-19      306  Alive    10459   Good       Siberian elm   \n",
       "22732  2015-05-19        9  Alive    10474   Poor       silver birch   \n",
       "4301   2015-05-19      307  Alive    10459   Good       Siberian elm   \n",
       "\n",
       "        latitude  longitude                    geometry  \n",
       "13800  40.821445 -73.892916  POINT (-73.89292 40.82144)  \n",
       "45386  40.825308 -73.897495  POINT (-73.89750 40.82531)  \n",
       "1890   40.823933 -73.897177  POINT (-73.89718 40.82393)  \n",
       "22732  40.814107 -73.889021  POINT (-73.88902 40.81411)  \n",
       "4301   40.824059 -73.897260  POINT (-73.89726 40.82406)  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geodf_tree_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59724f74-5f1e-435c-b843-f381a875dd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2157 entries, 0 to 6721\n",
      "Columns: 110 entries, zipcode to 2023-09-30\n",
      "dtypes: float64(105), int64(1), object(4)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_zillow_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e29ae5d9-9768-4590-a2f2-dd63b07dd712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zipcode</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>metro</th>\n",
       "      <th>countyname</th>\n",
       "      <th>2015-01-31</th>\n",
       "      <th>2015-02-28</th>\n",
       "      <th>2015-03-31</th>\n",
       "      <th>2015-04-30</th>\n",
       "      <th>2015-05-31</th>\n",
       "      <th>...</th>\n",
       "      <th>2022-12-31</th>\n",
       "      <th>2023-01-31</th>\n",
       "      <th>2023-02-28</th>\n",
       "      <th>2023-03-31</th>\n",
       "      <th>2023-04-30</th>\n",
       "      <th>2023-05-31</th>\n",
       "      <th>2023-06-30</th>\n",
       "      <th>2023-07-31</th>\n",
       "      <th>2023-08-31</th>\n",
       "      <th>2023-09-30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77494</td>\n",
       "      <td>TX</td>\n",
       "      <td>Katy</td>\n",
       "      <td>Houston-The Woodlands-Sugar Land, TX</td>\n",
       "      <td>Fort Bend County</td>\n",
       "      <td>1606.206406</td>\n",
       "      <td>1612.779844</td>\n",
       "      <td>1622.201575</td>\n",
       "      <td>1630.392427</td>\n",
       "      <td>1632.411500</td>\n",
       "      <td>...</td>\n",
       "      <td>1994.653463</td>\n",
       "      <td>2027.438438</td>\n",
       "      <td>2042.237444</td>\n",
       "      <td>2049.325559</td>\n",
       "      <td>2016.531345</td>\n",
       "      <td>2023.438976</td>\n",
       "      <td>2031.558202</td>\n",
       "      <td>2046.144009</td>\n",
       "      <td>2053.486247</td>\n",
       "      <td>2055.771355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77449</td>\n",
       "      <td>TX</td>\n",
       "      <td>Katy</td>\n",
       "      <td>Houston-The Woodlands-Sugar Land, TX</td>\n",
       "      <td>Harris County</td>\n",
       "      <td>1257.814660</td>\n",
       "      <td>1255.268025</td>\n",
       "      <td>1262.170452</td>\n",
       "      <td>1274.955754</td>\n",
       "      <td>1285.526052</td>\n",
       "      <td>...</td>\n",
       "      <td>1749.697900</td>\n",
       "      <td>1738.217986</td>\n",
       "      <td>1747.305840</td>\n",
       "      <td>1758.407295</td>\n",
       "      <td>1758.891075</td>\n",
       "      <td>1762.980879</td>\n",
       "      <td>1771.751591</td>\n",
       "      <td>1779.338402</td>\n",
       "      <td>1795.384582</td>\n",
       "      <td>1799.631140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77084</td>\n",
       "      <td>TX</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Houston-The Woodlands-Sugar Land, TX</td>\n",
       "      <td>Harris County</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1701.217520</td>\n",
       "      <td>1706.900064</td>\n",
       "      <td>1706.067787</td>\n",
       "      <td>1723.722320</td>\n",
       "      <td>1735.484670</td>\n",
       "      <td>1752.132904</td>\n",
       "      <td>1756.990323</td>\n",
       "      <td>1754.429516</td>\n",
       "      <td>1757.602011</td>\n",
       "      <td>1755.031490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11385</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York-Newark-Jersey City, NY-NJ-PA</td>\n",
       "      <td>Queens County</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2087.527084</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2149.924252</td>\n",
       "      <td>2166.263698</td>\n",
       "      <td>...</td>\n",
       "      <td>2935.808220</td>\n",
       "      <td>2895.699421</td>\n",
       "      <td>2873.209025</td>\n",
       "      <td>2881.906361</td>\n",
       "      <td>2913.546218</td>\n",
       "      <td>2963.964134</td>\n",
       "      <td>3005.735342</td>\n",
       "      <td>3034.413822</td>\n",
       "      <td>3064.476503</td>\n",
       "      <td>3079.585783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>78660</td>\n",
       "      <td>TX</td>\n",
       "      <td>Pflugerville</td>\n",
       "      <td>Austin-Round Rock-Georgetown, TX</td>\n",
       "      <td>Travis County</td>\n",
       "      <td>1399.372678</td>\n",
       "      <td>1411.391149</td>\n",
       "      <td>1396.562265</td>\n",
       "      <td>1390.741122</td>\n",
       "      <td>1403.065652</td>\n",
       "      <td>...</td>\n",
       "      <td>2087.219530</td>\n",
       "      <td>2107.491824</td>\n",
       "      <td>2103.020690</td>\n",
       "      <td>2109.932132</td>\n",
       "      <td>2099.065912</td>\n",
       "      <td>2110.786195</td>\n",
       "      <td>2112.792210</td>\n",
       "      <td>2113.710515</td>\n",
       "      <td>2098.939433</td>\n",
       "      <td>2094.435442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   zipcode state          city                                  metro  \\\n",
       "0    77494    TX          Katy   Houston-The Woodlands-Sugar Land, TX   \n",
       "1    77449    TX          Katy   Houston-The Woodlands-Sugar Land, TX   \n",
       "2    77084    TX       Houston   Houston-The Woodlands-Sugar Land, TX   \n",
       "4    11385    NY      New York  New York-Newark-Jersey City, NY-NJ-PA   \n",
       "5    78660    TX  Pflugerville       Austin-Round Rock-Georgetown, TX   \n",
       "\n",
       "         countyname   2015-01-31   2015-02-28   2015-03-31   2015-04-30  \\\n",
       "0  Fort Bend County  1606.206406  1612.779844  1622.201575  1630.392427   \n",
       "1     Harris County  1257.814660  1255.268025  1262.170452  1274.955754   \n",
       "2     Harris County          NaN          NaN          NaN          NaN   \n",
       "4     Queens County          NaN  2087.527084          NaN  2149.924252   \n",
       "5     Travis County  1399.372678  1411.391149  1396.562265  1390.741122   \n",
       "\n",
       "    2015-05-31  ...   2022-12-31   2023-01-31   2023-02-28   2023-03-31  \\\n",
       "0  1632.411500  ...  1994.653463  2027.438438  2042.237444  2049.325559   \n",
       "1  1285.526052  ...  1749.697900  1738.217986  1747.305840  1758.407295   \n",
       "2          NaN  ...  1701.217520  1706.900064  1706.067787  1723.722320   \n",
       "4  2166.263698  ...  2935.808220  2895.699421  2873.209025  2881.906361   \n",
       "5  1403.065652  ...  2087.219530  2107.491824  2103.020690  2109.932132   \n",
       "\n",
       "    2023-04-30   2023-05-31   2023-06-30   2023-07-31   2023-08-31  \\\n",
       "0  2016.531345  2023.438976  2031.558202  2046.144009  2053.486247   \n",
       "1  1758.891075  1762.980879  1771.751591  1779.338402  1795.384582   \n",
       "2  1735.484670  1752.132904  1756.990323  1754.429516  1757.602011   \n",
       "4  2913.546218  2963.964134  3005.735342  3034.413822  3064.476503   \n",
       "5  2099.065912  2110.786195  2112.792210  2113.710515  2098.939433   \n",
       "\n",
       "    2023-09-30  \n",
       "0  2055.771355  \n",
       "1  1799.631140  \n",
       "2  1755.031490  \n",
       "4  3079.585783  \n",
       "5  2094.435442  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zillow_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e685942c-26dc-40db-84c2-a71aa3340806",
   "metadata": {},
   "source": [
    "## Part 2: Storing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527a251c-f337-4b24-bb41-96ee4621a9bd",
   "metadata": {},
   "source": [
    "### Creating Tables\n",
    "\n",
    "\n",
    "These are just a couple of options to creating your tables; you can use one or the other, a different method, or a combination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232a2d89-b276-4d44-a0ef-3631eb686e84",
   "metadata": {},
   "source": [
    "#### Option 2: SQLAlchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d41c42e1-4ad4-4c43-a2ba-1dbcac1de557",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base = declarative_base()\n",
    "\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Float, Date, MetaData, Table\n",
    "from geoalchemy2 import Geometry\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "\n",
    "class ZipcodeArea(Base):\n",
    "    __tablename__ = 'zipcode_areas'  # Replace with your actual table name\n",
    "    # Assuming 'zipcode' is a unique identifier for each row\n",
    "    zipcode = Column(Integer, primary_key=True)\n",
    "    city = Column(String)\n",
    "    population = Column(Integer)\n",
    "    area = Column(Float)\n",
    "    county = Column(String)\n",
    "    geometry = Column(Geometry('POLYGON', srid=4326))  # Adjust the geometry type if needed\n",
    "\n",
    "class NYC311Complaints(Base):\n",
    "    __tablename__ = 'nyc311_complaints'\n",
    "    id_NYC311 = Column(Integer, primary_key=True)\n",
    "    date = Column(Date)\n",
    "    complaint_type = Column(String)\n",
    "    zipcode = Column(Integer)\n",
    "    latitude = Column(Float)\n",
    "    longitude = Column(Float)\n",
    "    geometry = Column(Geometry(geometry_type='POINT', srid=4326))\n",
    "\n",
    "class Tree(Base):\n",
    "    __tablename__ = 'trees'\n",
    "    tree_id = Column(Integer, primary_key=True)\n",
    "    date = Column(Date)\n",
    "    status = Column(String)\n",
    "    zipcode = Column(Integer)\n",
    "    health = Column(String)\n",
    "    spc_common = Column(String)\n",
    "    latitude = Column(Float)\n",
    "    longitude = Column(Float)\n",
    "    geometry = Column(Geometry(geometry_type='POINT', srid=4326))\n",
    "\n",
    "class Rent(Base):\n",
    "    __tablename__ = 'rents'\n",
    "    zipcode = Column(Integer, primary_key=True)\n",
    "    state = Column(String)\n",
    "    city = Column(String)\n",
    "    metro = Column(String)\n",
    "    countyname = Column(String)\n",
    "    date = Column(Date)\n",
    "    rent = Column(Float)\n",
    "\n",
    "engine = create_engine(DB_URL)\n",
    "Base.metadata.create_all(engine)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e88a50c-9528-4a5c-9a52-b96781ee8985",
   "metadata": {},
   "source": [
    "### Add Data to Database\n",
    "\n",
    "These are just a couple of options to write data to your tables; you can use one or the other, a different method, or a combination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9207cec5",
   "metadata": {},
   "source": [
    "Add ZipCode Data to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c50667",
   "metadata": {},
   "outputs": [],
   "source": [
    "Session = db.orm.sessionmaker(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6126be5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from shapely import wkt\n",
    "from sqlalchemy.dialects.postgresql import insert\n",
    "\n",
    "geodf_zipcode_data['geometry'] = geodf_zipcode_data['geometry'].apply(lambda geom: geom.wkt)\n",
    "for index, row in geodf_zipcode_data.iterrows():\n",
    "    insert_stmt = insert(ZipcodeArea).values(\n",
    "        zipcode=row['zipcode'],\n",
    "        city=row['city'],\n",
    "        population=row['population'],\n",
    "        area=row['area'],\n",
    "        county=row['county'],\n",
    "        geometry=row['geometry']\n",
    "    )\n",
    "    on_conflict_stmt = insert_stmt.on_conflict_do_update(\n",
    "        index_elements=['zipcode'],  # Unique constraint or column(s) causing conflict\n",
    "        set_=dict(\n",
    "            city=row['city'],\n",
    "            population=row['population'],\n",
    "            area=row['area'],\n",
    "            county=row['county'],\n",
    "            geometry=row['geometry']\n",
    "        )\n",
    "    )\n",
    "    session.execute(on_conflict_stmt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc0d934",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f6e404",
   "metadata": {},
   "source": [
    "Add NYC 311 Complaint Data to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dce0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.dialects.postgresql import insert\n",
    "# Convert geometry column to WKT format\n",
    "geodf_311_data['geometry'] = geodf_311_data['geometry'].apply(lambda geom: geom.wkt)\n",
    "\n",
    "def insert_batch(session, model, data, batch_size=200000):\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        batch = data.iloc[i:i+batch_size].to_dict(orient='records')\n",
    "\n",
    "        for record in batch:\n",
    "            stmt = insert(model).values(record)\n",
    "            do_nothing_stmt = stmt.on_conflict_do_nothing(index_elements=['id_NYC311'])\n",
    "            session.execute(do_nothing_stmt)\n",
    "\n",
    "        session.commit()\n",
    "\n",
    "# Insert data in batches\n",
    "insert_batch(session, NYC311Complaints, geodf_311_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d792f6eb",
   "metadata": {},
   "source": [
    "Add Tree Data to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77174d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_tree_data['geometry'] = geodf_tree_data['geometry'].apply(lambda geom: geom.wkt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba74275",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for index, row in geodf_tree_data.iterrows():\n",
    "    # Create a TreeData object for each row\n",
    "    tree = Tree(\n",
    "        tree_id=row['tree_id'],\n",
    "        date=row['date'],\n",
    "        status=row['status'],\n",
    "        zipcode=row['zipcode'],\n",
    "        health=row['health'],\n",
    "        spc_common=row['spc_common'],\n",
    "        latitude=row['latitude'],\n",
    "        longitude=row['longitude'],\n",
    "        geometry=row['geometry']\n",
    "    )\n",
    "    # Add each TreeData object to the session\n",
    "    session.add(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea33daf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a340ea",
   "metadata": {},
   "source": [
    "Add Zillow Rent Data to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5181fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each row in the DataFrame for Zillow rent data\n",
    "for index, row in df_zillow_data.iterrows():\n",
    "    # Create a ZillowRent object for each row (assuming ZillowRent is the model class)\n",
    "    rent = Rent(\n",
    "        ZipCode=row['zip'],\n",
    "        State=row['state'],\n",
    "        City=row['city'],\n",
    "        Metro=row['Metro'],\n",
    "        CountyName=row['CountyName']\n",
    "    )\n",
    "    # Add each ZillowRent object to the session\n",
    "    session.add(rent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e454a2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commit the session to save all added objects to the database\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb63b553-0c64-4da8-9fc7-41555d89d853",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac7e12b-e251-4f08-8dc5-601db30c2089",
   "metadata": {},
   "source": [
    "### Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ce8548-4aba-4bf9-992c-dedd0f249db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to write the queries to file\n",
    "def write_query_to_file(query, outfile):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b2adbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11226, 49279)\n",
      "(10467, 47364)\n",
      "(10468, 44045)\n",
      "(10452, 43858)\n",
      "(11385, 43587)\n",
      "(10457, 41497)\n",
      "(10458, 41152)\n",
      "(11207, 39922)\n",
      "(10456, 39756)\n",
      "(11201, 39230)\n",
      "(10453, 38065)\n",
      "(11208, 36494)\n",
      "(10031, 33798)\n",
      "(11221, 33073)\n",
      "(10466, 32515)\n",
      "(10032, 31973)\n",
      "(10025, 30935)\n",
      "(10462, 30720)\n",
      "(11238, 30114)\n",
      "(11230, 29440)\n",
      "(11368, 29235)\n",
      "(11220, 28845)\n",
      "(10019, 28113)\n",
      "(11216, 28068)\n",
      "(11225, 28030)\n",
      "(11235, 27685)\n",
      "(11212, 27233)\n",
      "(10460, 26955)\n",
      "(10463, 26954)\n",
      "(10023, 26805)\n",
      "(11203, 26749)\n",
      "(11214, 26632)\n",
      "(11377, 26222)\n",
      "(10027, 25785)\n",
      "(11101, 25752)\n",
      "(11213, 25733)\n",
      "(10002, 25553)\n",
      "(11211, 25467)\n",
      "(11206, 25334)\n",
      "(10472, 25334)\n",
      "(11234, 25282)\n",
      "(11222, 25262)\n",
      "(11209, 25145)\n",
      "(11215, 25127)\n",
      "(11218, 24989)\n",
      "(11233, 24875)\n",
      "(11223, 24058)\n",
      "(11373, 23929)\n",
      "(10033, 23654)\n",
      "(11237, 23320)\n",
      "(11229, 22655)\n",
      "(11236, 22375)\n",
      "(10461, 22256)\n",
      "(10034, 22248)\n",
      "(10011, 22088)\n",
      "(11204, 21658)\n",
      "(10003, 21570)\n",
      "(10026, 21260)\n",
      "(10469, 21187)\n",
      "(10009, 20997)\n",
      "(11210, 20924)\n",
      "(10029, 20808)\n",
      "(10451, 20695)\n",
      "(10036, 20683)\n",
      "(11372, 20405)\n",
      "(10459, 20278)\n",
      "(11217, 20230)\n",
      "(10040, 19833)\n",
      "(10314, 19701)\n",
      "(11231, 19555)\n",
      "(11432, 19522)\n",
      "(11419, 19477)\n",
      "(11420, 19275)\n",
      "(11378, 19032)\n",
      "(11375, 18921)\n",
      "(11219, 18827)\n",
      "(11355, 18702)\n",
      "(10455, 18392)\n",
      "(11366, 18382)\n",
      "(10035, 18266)\n",
      "(10030, 18015)\n",
      "(10016, 17075)\n",
      "(11421, 17042)\n",
      "(11205, 17008)\n",
      "(10312, 16709)\n",
      "(11434, 16612)\n",
      "(11435, 16545)\n",
      "(11414, 16135)\n",
      "(10024, 16041)\n",
      "(11691, 15841)\n",
      "(10473, 15546)\n",
      "(10306, 15538)\n",
      "(11103, 15300)\n",
      "(11106, 14936)\n",
      "(11379, 14586)\n",
      "(11224, 14417)\n",
      "(11433, 14266)\n",
      "(11105, 14247)\n",
      "(10465, 14021)\n",
      "(10028, 13965)\n",
      "(11354, 13895)\n",
      "(10301, 13619)\n",
      "(10454, 13603)\n",
      "(10014, 13360)\n",
      "(10001, 13126)\n",
      "(11249, 12938)\n",
      "(11357, 12708)\n",
      "(10304, 12680)\n",
      "(11369, 12563)\n",
      "(10013, 12336)\n",
      "(11232, 12241)\n",
      "(11102, 12219)\n",
      "(11374, 12173)\n",
      "(10039, 11956)\n",
      "(11417, 11914)\n",
      "(11365, 11857)\n",
      "(10128, 11850)\n",
      "(11228, 11833)\n",
      "(11418, 11663)\n",
      "(10012, 11510)\n",
      "(11239, 11020)\n",
      "(10305, 10748)\n",
      "(11358, 10506)\n",
      "(11413, 10489)\n",
      "(11412, 10359)\n",
      "(10309, 9866)\n",
      "(11356, 9836)\n",
      "(10022, 9686)\n",
      "(11104, 9599)\n",
      "(10021, 9587)\n",
      "(10470, 8933)\n",
      "(11361, 8928)\n",
      "(11367, 8742)\n",
      "(11416, 8467)\n",
      "(11423, 8306)\n",
      "(11694, 8252)\n",
      "(10065, 8041)\n",
      "(10037, 7939)\n",
      "(10010, 7907)\n",
      "(11422, 7816)\n",
      "(10018, 7593)\n",
      "(10471, 7550)\n",
      "(11436, 7514)\n",
      "(11370, 7235)\n",
      "(11364, 6954)\n",
      "(10474, 6781)\n",
      "(10308, 6713)\n",
      "(10017, 6680)\n",
      "(10310, 6679)\n",
      "(10038, 6675)\n",
      "(10303, 6609)\n",
      "(10302, 6410)\n",
      "(11429, 6025)\n",
      "(10075, 5703)\n",
      "(11415, 5633)\n",
      "(11692, 5595)\n",
      "(11411, 5513)\n",
      "(11428, 5359)\n",
      "(11427, 4951)\n",
      "(11693, 4200)\n",
      "(11426, 4071)\n",
      "(10007, 4024)\n",
      "(11360, 3805)\n",
      "(10307, 3735)\n",
      "(10475, 3734)\n",
      "(11362, 3191)\n",
      "(11430, 3064)\n",
      "(10464, 2534)\n",
      "(10004, 2487)\n",
      "(11004, 2360)\n",
      "(10005, 2082)\n",
      "(11363, 1865)\n",
      "(11109, 1837)\n",
      "(10006, 1578)\n",
      "(10044, 1040)\n",
      "(11001, 812)\n",
      "(10282, 742)\n",
      "(10000, 689)\n",
      "(11040, 642)\n",
      "(10069, 593)\n",
      "(10280, 555)\n",
      "(10020, 432)\n",
      "(10169, 412)\n",
      "(10121, 286)\n",
      "(10107, 228)\n",
      "(10278, 204)\n",
      "(10105, 164)\n",
      "(10153, 153)\n",
      "(11359, 146)\n",
      "(11697, 111)\n",
      "(10172, 101)\n",
      "(10151, 83)\n",
      "(10103, 81)\n",
      "(10281, 68)\n",
      "(10168, 60)\n",
      "(10118, 52)\n",
      "(12345, 51)\n",
      "(11005, 50)\n",
      "(10120, 48)\n",
      "(10106, 45)\n",
      "(11251, 41)\n",
      "(10162, 39)\n",
      "(10119, 35)\n",
      "(10271, 34)\n",
      "(10041, 33)\n",
      "(10112, 28)\n",
      "(10165, 27)\n",
      "(10045, 27)\n",
      "(10171, 24)\n",
      "(10110, 24)\n",
      "(10170, 24)\n",
      "(10048, 23)\n",
      "(10154, 22)\n",
      "(10178, 22)\n",
      "(10158, 21)\n",
      "(11371, 20)\n",
      "(11241, 18)\n",
      "(10123, 17)\n",
      "(10179, 16)\n",
      "(10174, 16)\n",
      "(10279, 15)\n",
      "(10177, 13)\n",
      "(10115, 12)\n",
      "(10111, 12)\n",
      "(11695, 11)\n",
      "(11242, 11)\n",
      "(10176, 8)\n",
      "(10152, 7)\n",
      "(10166, 7)\n",
      "(10173, 5)\n",
      "(10803, 4)\n",
      "(10122, 4)\n",
      "(10155, 4)\n",
      "(10167, 4)\n",
      "(10055, 2)\n",
      "(10175, 1)\n",
      "(10080, 1)\n",
      "(10550, 1)\n",
      "(29601, 1)\n",
      "(33496, 1)\n",
      "(45040, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sqlalchemy.sql import text\n",
    "\n",
    "# Define the directory where query files will be saved\n",
    "# Creates the directory if it does not exist\n",
    "QUERY_DIR = pathlib.Path(\"queries\")\n",
    "QUERY_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Define the SQL query for Query 1\n",
    "# This query finds the number of 311 complaints per zip code \n",
    "# between 2022-10-01 and 2023-09-30 and orders them in descending order\n",
    "QUERY_1 = \"\"\"\n",
    "SELECT zipcode, COUNT(*) AS complaint_count\n",
    "FROM nyc311_complaints\n",
    "WHERE date BETWEEN '2022-10-01' AND '2023-09-30'\n",
    "GROUP BY zipcode\n",
    "ORDER BY complaint_count DESC;\n",
    "\"\"\"\n",
    "\n",
    "# Function to write the SQL query to a file\n",
    "def write_query_to_file(query, outfile):\n",
    "    with open(outfile, 'w') as file:\n",
    "        file.write(query)\n",
    "\n",
    "# File path for saving the query\n",
    "QUERY_1_FILENAME = QUERY_DIR / \"complaints_per_zipcode.sql\"\n",
    "\n",
    "# Execute the query and print the results\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(QUERY_1))\n",
    "    for row in result:\n",
    "        print(row)\n",
    "\n",
    "# Write the query to a file\n",
    "write_query_to_file(QUERY_1, QUERY_1_FILENAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f63b95f",
   "metadata": {},
   "source": [
    "### Query 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "682b9035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10309, 7839)\n",
      "(10312, 6946)\n",
      "(10469, 4703)\n",
      "(11230, 4684)\n",
      "(10314, 3964)\n",
      "(10306, 3767)\n",
      "(10465, 3461)\n",
      "(11229, 3395)\n",
      "(11375, 3324)\n",
      "(10461, 3315)\n"
     ]
    }
   ],
   "source": [
    "# Query 2: Finding the top 10 zip codes with the most trees\n",
    "# This query aims to identify which 10 zip codes have the highest number of trees\n",
    "\n",
    "QUERY_2 = \"\"\"\n",
    "SELECT zipcode, COUNT(*) AS tree_count\n",
    "FROM trees\n",
    "GROUP BY zipcode\n",
    "ORDER BY tree_count DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "# File path for saving the query\n",
    "QUERY_2_FILENAME = QUERY_DIR / \"top_10_zipcodes_by_trees.sql\"\n",
    "\n",
    "# Execute the query and print the results\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(QUERY_2))\n",
    "    for row in result:\n",
    "        print(row)\n",
    "\n",
    "# Write the query to a file\n",
    "write_query_to_file(QUERY_2, QUERY_2_FILENAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7e33e5",
   "metadata": {},
   "source": [
    "### Query 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f11a0c05",
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "(psycopg2.errors.UndefinedFunction) operator does not exist: integer = character varying\nLINE 11: JOIN zillow_rent zr ON ttz.zipcode = zr.\"ZipCode\"\n                                            ^\nHINT:  No operator matches the given name and argument types. You might need to add explicit type casts.\n\n[SQL: \nWITH TopTreeZipCodes AS (\n    SELECT zipcode\n    FROM trees\n    GROUP BY zipcode\n    ORDER BY COUNT(*) DESC\n    LIMIT 10\n)\nSELECT ttz.zipcode, ROUND(AVG(r.rent), 2) AS average_rent\nFROM TopTreeZipCodes ttz\nJOIN zillow_rent zr ON ttz.zipcode = zr.\"ZipCode\"\nWHERE zr.date BETWEEN '2023-08-01' AND '2023-08-31'\nGROUP BY ttz.zipcode\nORDER BY COUNT(*) DESC;\n]\n(Background on this error at: https://sqlalche.me/e/14/f405)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUndefinedFunction\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1819\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1818\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1819\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdialect\u001b[39m.\u001b[39mdo_execute(\n\u001b[1;32m   1820\u001b[0m             cursor, statement, parameters, context\n\u001b[1;32m   1821\u001b[0m         )\n\u001b[1;32m   1823\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/default.py:732\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_execute\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 732\u001b[0m     cursor\u001b[39m.\u001b[39mexecute(statement, parameters)\n",
      "\u001b[0;31mUndefinedFunction\u001b[0m: operator does not exist: integer = character varying\nLINE 11: JOIN zillow_rent zr ON ttz.zipcode = zr.\"ZipCode\"\n                                            ^\nHINT:  No operator matches the given name and argument types. You might need to add explicit type casts.\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m# Execute the query and print the results\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39mwith\u001b[39;00m engine\u001b[39m.\u001b[39mconnect() \u001b[39mas\u001b[39;00m conn:\n\u001b[0;32m---> 26\u001b[0m     result \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mexecute(text(QUERY_3))\n\u001b[1;32m     27\u001b[0m     \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m result:\n\u001b[1;32m     28\u001b[0m         \u001b[39mprint\u001b[39m(row)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1306\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[1;32m   1302\u001b[0m     util\u001b[39m.\u001b[39mraise_(\n\u001b[1;32m   1303\u001b[0m         exc\u001b[39m.\u001b[39mObjectNotExecutableError(statement), replace_context\u001b[39m=\u001b[39merr\n\u001b[1;32m   1304\u001b[0m     )\n\u001b[1;32m   1305\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1306\u001b[0m     \u001b[39mreturn\u001b[39;00m meth(\u001b[39mself\u001b[39m, multiparams, params, _EMPTY_EXECUTION_OPTS)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/sql/elements.py:332\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[0;34m(self, connection, multiparams, params, execution_options, _force)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_execute_on_connection\u001b[39m(\n\u001b[1;32m    329\u001b[0m     \u001b[39mself\u001b[39m, connection, multiparams, params, execution_options, _force\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    330\u001b[0m ):\n\u001b[1;32m    331\u001b[0m     \u001b[39mif\u001b[39;00m _force \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupports_execution:\n\u001b[0;32m--> 332\u001b[0m         \u001b[39mreturn\u001b[39;00m connection\u001b[39m.\u001b[39m_execute_clauseelement(\n\u001b[1;32m    333\u001b[0m             \u001b[39mself\u001b[39m, multiparams, params, execution_options\n\u001b[1;32m    334\u001b[0m         )\n\u001b[1;32m    335\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    336\u001b[0m         \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mObjectNotExecutableError(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1498\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[0;34m(self, elem, multiparams, params, execution_options)\u001b[0m\n\u001b[1;32m   1486\u001b[0m compiled_cache \u001b[39m=\u001b[39m execution_options\u001b[39m.\u001b[39mget(\n\u001b[1;32m   1487\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcompiled_cache\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_compiled_cache\n\u001b[1;32m   1488\u001b[0m )\n\u001b[1;32m   1490\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39m_compile_w_cache(\n\u001b[1;32m   1491\u001b[0m     dialect\u001b[39m=\u001b[39mdialect,\n\u001b[1;32m   1492\u001b[0m     compiled_cache\u001b[39m=\u001b[39mcompiled_cache,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1496\u001b[0m     linting\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdialect\u001b[39m.\u001b[39mcompiler_linting \u001b[39m|\u001b[39m compiler\u001b[39m.\u001b[39mWARN_LINTING,\n\u001b[1;32m   1497\u001b[0m )\n\u001b[0;32m-> 1498\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_execute_context(\n\u001b[1;32m   1499\u001b[0m     dialect,\n\u001b[1;32m   1500\u001b[0m     dialect\u001b[39m.\u001b[39mexecution_ctx_cls\u001b[39m.\u001b[39m_init_compiled,\n\u001b[1;32m   1501\u001b[0m     compiled_sql,\n\u001b[1;32m   1502\u001b[0m     distilled_params,\n\u001b[1;32m   1503\u001b[0m     execution_options,\n\u001b[1;32m   1504\u001b[0m     compiled_sql,\n\u001b[1;32m   1505\u001b[0m     distilled_params,\n\u001b[1;32m   1506\u001b[0m     elem,\n\u001b[1;32m   1507\u001b[0m     extracted_params,\n\u001b[1;32m   1508\u001b[0m     cache_hit\u001b[39m=\u001b[39mcache_hit,\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1510\u001b[0m \u001b[39mif\u001b[39;00m has_events:\n\u001b[1;32m   1511\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mafter_execute(\n\u001b[1;32m   1512\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m   1513\u001b[0m         elem,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1517\u001b[0m         ret,\n\u001b[1;32m   1518\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1862\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1859\u001b[0m             branched\u001b[39m.\u001b[39mclose()\n\u001b[1;32m   1861\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 1862\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_dbapi_exception(\n\u001b[1;32m   1863\u001b[0m         e, statement, parameters, cursor, context\n\u001b[1;32m   1864\u001b[0m     )\n\u001b[1;32m   1866\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/base.py:2043\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   2041\u001b[0m     util\u001b[39m.\u001b[39mraise_(newraise, with_traceback\u001b[39m=\u001b[39mexc_info[\u001b[39m2\u001b[39m], from_\u001b[39m=\u001b[39me)\n\u001b[1;32m   2042\u001b[0m \u001b[39melif\u001b[39;00m should_wrap:\n\u001b[0;32m-> 2043\u001b[0m     util\u001b[39m.\u001b[39mraise_(\n\u001b[1;32m   2044\u001b[0m         sqlalchemy_exception, with_traceback\u001b[39m=\u001b[39mexc_info[\u001b[39m2\u001b[39m], from_\u001b[39m=\u001b[39me\n\u001b[1;32m   2045\u001b[0m     )\n\u001b[1;32m   2046\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2047\u001b[0m     util\u001b[39m.\u001b[39mraise_(exc_info[\u001b[39m1\u001b[39m], with_traceback\u001b[39m=\u001b[39mexc_info[\u001b[39m2\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/util/compat.py:208\u001b[0m, in \u001b[0;36mraise_\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    205\u001b[0m     exception\u001b[39m.\u001b[39m__cause__ \u001b[39m=\u001b[39m replace_context\n\u001b[1;32m    207\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 208\u001b[0m     \u001b[39mraise\u001b[39;00m exception\n\u001b[1;32m    209\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m     \u001b[39m# credit to\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     \u001b[39m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[1;32m    212\u001b[0m     \u001b[39m# as the __traceback__ object creates a cycle\u001b[39;00m\n\u001b[1;32m    213\u001b[0m     \u001b[39mdel\u001b[39;00m exception, replace_context, from_, with_traceback\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1819\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1817\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   1818\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1819\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdialect\u001b[39m.\u001b[39mdo_execute(\n\u001b[1;32m   1820\u001b[0m             cursor, statement, parameters, context\n\u001b[1;32m   1821\u001b[0m         )\n\u001b[1;32m   1823\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n\u001b[1;32m   1824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mafter_cursor_execute(\n\u001b[1;32m   1825\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m   1826\u001b[0m         cursor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1830\u001b[0m         context\u001b[39m.\u001b[39mexecutemany,\n\u001b[1;32m   1831\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/default.py:732\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_execute\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 732\u001b[0m     cursor\u001b[39m.\u001b[39mexecute(statement, parameters)\n",
      "\u001b[0;31mProgrammingError\u001b[0m: (psycopg2.errors.UndefinedFunction) operator does not exist: integer = character varying\nLINE 11: JOIN zillow_rent zr ON ttz.zipcode = zr.\"ZipCode\"\n                                            ^\nHINT:  No operator matches the given name and argument types. You might need to add explicit type casts.\n\n[SQL: \nWITH TopTreeZipCodes AS (\n    SELECT zipcode\n    FROM trees\n    GROUP BY zipcode\n    ORDER BY COUNT(*) DESC\n    LIMIT 10\n)\nSELECT ttz.zipcode, ROUND(AVG(r.rent), 2) AS average_rent\nFROM TopTreeZipCodes ttz\nJOIN zillow_rent zr ON ttz.zipcode = zr.\"ZipCode\"\nWHERE zr.date BETWEEN '2023-08-01' AND '2023-08-31'\nGROUP BY ttz.zipcode\nORDER BY COUNT(*) DESC;\n]\n(Background on this error at: https://sqlalche.me/e/14/f405)"
     ]
    }
   ],
   "source": [
    "# Query 3: Calculating average rent in the areas with the most trees for August 2023\n",
    "# This query identifies the average rent by zip code for the top 10 zip codes with the most trees, \n",
    "# specifically for the month of August 2023\n",
    "\n",
    "QUERY_3 = \"\"\"\n",
    "WITH TopTreeZipCodes AS (\n",
    "    SELECT zipcode\n",
    "    FROM trees\n",
    "    GROUP BY zipcode\n",
    "    ORDER BY COUNT(*) DESC\n",
    "    LIMIT 10\n",
    ")\n",
    "SELECT ttz.zipcode, ROUND(AVG(r.rent), 2) AS average_rent\n",
    "FROM TopTreeZipCodes ttz\n",
    "JOIN zillow_rent zr ON ttz.zipcode = zr.\"ZipCode\"\n",
    "WHERE zr.date BETWEEN '2023-08-01' AND '2023-08-31'\n",
    "GROUP BY ttz.zipcode\n",
    "ORDER BY COUNT(*) DESC;\n",
    "\"\"\"\n",
    "\n",
    "# File path for saving the query\n",
    "QUERY_3_FILENAME = QUERY_DIR / \"average_rent_in_green_areas.sql\"\n",
    "\n",
    "# Execute the query and print the results\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(QUERY_3))\n",
    "    for row in result:\n",
    "        print(row)\n",
    "\n",
    "# Write the query to a file\n",
    "write_query_to_file(QUERY_3, QUERY_3_FILENAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5c0bbb",
   "metadata": {},
   "source": [
    "### Query 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29adf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 4: Correlation between area's rent, tree count, and number of 311 complaints\n",
    "# This query finds the 5 zip codes with the lowest and highest average rent for January 2023,\n",
    "# along with the tree count and complaint count for each zip code\n",
    "\n",
    "QUERY_4 = \"\"\"\n",
    "WITH RentRanking AS (\n",
    "    SELECT zipcode, ROUND(AVG(rent), 2) AS average_rent,\n",
    "    RANK() OVER (ORDER BY AVG(rent)) AS rent_rank\n",
    "    FROM zillow_rent\n",
    "    WHERE date BETWEEN '2023-01-01' AND '2023-01-31'\n",
    "    GROUP BY zipcode\n",
    ")\n",
    "SELECT rr.zipcode, rr.average_rent, \n",
    "       (SELECT COUNT(*) FROM tree_data WHERE zipcode = rr.zipcode) AS tree_count,\n",
    "       (SELECT COUNT(*) FROM nyc311_complaints WHERE zipcode = rr.zipcode AND date BETWEEN '2023-01-01' AND '2023-01-31') AS complaint_count\n",
    "FROM RentRanking rr\n",
    "WHERE rr.rent_rank <= 5 OR rr.rent_rank >= (SELECT MAX(rent_rank) - 4 FROM RentRanking)\n",
    "ORDER BY rr.average_rent;\n",
    "\"\"\"\n",
    "\n",
    "# File path for saving the query\n",
    "QUERY_4_FILENAME = QUERY_DIR / \"rent_tree_complaint_correlation.sql\"\n",
    "\n",
    "# Execute the query and print the results\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(QUERY_4))\n",
    "    for row in result:\n",
    "        print(row)\n",
    "\n",
    "# Write the query to a file\n",
    "write_query_to_file(QUERY_4, QUERY_4_FILENAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd939d04",
   "metadata": {},
   "source": [
    "### Query 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eacaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 5: Identifying areas with the most greenery using spatial join\n",
    "# This query rewrites Query 2 to include a spatial join between the trees table and the zipcodes table\n",
    "# to determine which trees are located within the boundary of a zipcode\n",
    "\n",
    "QUERY_5 = \"\"\"\n",
    "WITH TreeCount AS (\n",
    "    SELECT z.zipcode, COUNT(t.id) AS tree_count\n",
    "    FROM zipcodes z\n",
    "    JOIN tree_data t ON ST_Within(t.geom, z.geom)\n",
    "    GROUP BY z.zipcode\n",
    ")\n",
    "SELECT zipcode, tree_count\n",
    "FROM TreeCount\n",
    "ORDER BY tree_count DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "# File path for saving the query\n",
    "QUERY_5_FILENAME = QUERY_DIR / \"greenery_areas_with_spatial_join.sql\"\n",
    "\n",
    "# Execute the query and print the results\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(QUERY_5))\n",
    "    for row in result:\n",
    "        print(row)\n",
    "\n",
    "# Write the query to a file\n",
    "write_query_to_file(QUERY_5, QUERY_5_FILENAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9b5bed",
   "metadata": {},
   "source": [
    "### Query 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0abc857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 6: Finding trees within a Â½ mile radius of a specific coordinate point\n",
    "# This query identifies which trees are within a Â½ mile radius of the given latitude and longitude\n",
    "\n",
    "QUERY_6 = \"\"\"\n",
    "SELECT id, species, health, status, geom\n",
    "FROM tree_data\n",
    "WHERE ST_DWithin(\n",
    "    geom,\n",
    "    ST_SetSRID(ST_MakePoint(-73.96253174434912, 40.80737875669467), 4326),\n",
    "    0.5 * 1609.34  -- 0.5 miles in meters\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# File path for saving the query\n",
    "QUERY_6_FILENAME = QUERY_DIR / \"trees_nearby_coordinate.sql\"\n",
    "\n",
    "# Execute the query and print the results\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(QUERY_6))\n",
    "    for row in result:\n",
    "        print(row)\n",
    "\n",
    "# Write the query to a file\n",
    "write_query_to_file(QUERY_6, QUERY_6_FILENAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75223ce5-6ab5-4613-b6af-fa8e33bcc7d5",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21fcfed-ddbb-4908-a60e-ed7cbc6d5b00",
   "metadata": {},
   "source": [
    "### Visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0e2cde-e43b-407b-ab93-ff85a2dba469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a more descriptive name for your function\n",
    "def plot_visual_1(dataframe):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
    "    \n",
    "    # you may want to use matplotlib to plot your visualizations;\n",
    "    # there are also many other plot types (other \n",
    "    # than axes.plot) you can use\n",
    "    axes.plot(values, \"...\")\n",
    "    # there are other methods to use to label your axes, to style \n",
    "    # and set up axes labels, etc\n",
    "    axes.set_title(\"Some Descriptive Title\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed80755f-d1e1-4e53-8ef8-f5295c59a3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_1():\n",
    "    # Query your database for the data needed.\n",
    "    # You can put the data queried into a pandas/geopandas dataframe, if you wish\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a2632a-b516-4a6e-8b67-97116ab6fce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_1()\n",
    "plot_visual_1(some_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
