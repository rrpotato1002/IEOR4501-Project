{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4c5a136-e872-4846-9965-9ddc5251a0b3",
   "metadata": {},
   "source": [
    "# NYC Apartment Search\n",
    "\n",
    "_[Project prompt](https://docs.google.com/document/d/1BYVyFBDcTywdUlanH0ysfOrNWPgl7UkqXA7NeewTzxA/edit#heading=h.bpxu7uvknnbk)_\n",
    "\n",
    "_This scaffolding notebook may be used to help setup your final project. It's **totally optional** whether you make use of this or not._\n",
    "\n",
    "_If you do use this notebook, everything provided is optional as well - you may remove or add code as you wish._\n",
    "\n",
    "_**All code below should be consider \"pseudo-code\" - not functional by itself, and only an idea of a possible approach.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf11fa0-4684-4f5e-8048-0f4cc5f4f243",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f675d4b-794e-407c-aac9-b85c4a3975d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All import statements needed for the project, for example:\n",
    "\n",
    "import json\n",
    "import pathlib\n",
    "from requests.exceptions import ReadTimeout\n",
    "import time\n",
    "import geoalchemy2 as gdb\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import shapely\n",
    "import sqlalchemy as db\n",
    "from sodapy import Socrata\n",
    "import glob\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine,text\n",
    "\n",
    "from sqlalchemy.orm import declarative_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70a62277-51cf-48a2-81d2-9b2127088a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any constants you might need; some have been added for you\n",
    "\n",
    "# Where data files will be read from/written to - this should already exist\n",
    "DATA_DIR = pathlib.Path(\"data\")\n",
    "ZIPCODE_DATA_FILE = DATA_DIR / \"nyc_zipcodes.shp\"\n",
    "ZILLOW_DATA_FILE = DATA_DIR / \"zillow_rent_data.csv\"\n",
    "\n",
    "NYC_DATA_APP_TOKEN = \"xX3rCbSDM4vF0QEfgh09b2ZWW\"\n",
    "BASE_NYC_DATA_URL = \"https://data.cityofnewyork.us/\"\n",
    "NYC_DATA_311 = \"erm2-nwe9.geojson\"\n",
    "NYC_DATA_TREES = \"5rq2-4hqu.geojson\"\n",
    "\n",
    "DB_NAME = \"IEOR4501-XL\"\n",
    "\n",
    "DB_USER = \"postgres\"\n",
    "#DB_URL = f\"postgres+psycopg2://{DB_USER}@localhost/{DB_NAME}\"\n",
    "DB_URL = f\"postgresql://{DB_USER}@localhost/{DB_NAME}\"\n",
    "DB_SCHEMA_FILE = \"schema.sql\"\n",
    "\n",
    "QUERY_DIR = pathlib.Path(\"queries\")\n",
    "\n",
    "# directory where DB queries for Part 3 will be saved\n",
    "QUERY_DIR = pathlib.Path(\"queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd67cca9-ec72-44e3-83b8-b65f1ed5bb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the QUERY_DIRECTORY exists\n",
    "if not QUERY_DIR.exists():\n",
    "    QUERY_DIR.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52476a07-9bf2-4b7a-8cb7-93648bb4d303",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0f651ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloading data from small chunks\n",
    "def download_nyc_csv_data(year,starttime,endtime,url,filename):\n",
    "    filepath = f'{DATA_DIR}/{filename}_{year}.csv'\n",
    "    query=f\"\"\"\n",
    "    select * \n",
    "    where created_date between {starttime} \n",
    "    and {endtime}\n",
    "    \"\"\"\n",
    "\n",
    "    if not filename:\n",
    "        print(f\"Downloading {url} to {filename}...\")\n",
    "        client = Socrata( \"data.cityofnewyork.us\",\n",
    "                  \"xX3rCbSDM4vF0QEfgh09b2ZWW\",\n",
    "                  username=\"yirong263@gmail.com\",\n",
    "                  password=\"UTDYnmz*zn2u3g6\",\n",
    "                  timeout=60)\n",
    "        max_retries = 5\n",
    "        retry_wait = 10  # Initial wait time in seconds\n",
    "\n",
    "        while max_retries > 0:\n",
    "            try:    \n",
    "            # Set initial parameters for the SoQL query\n",
    "                limit = 1000000  # Example limit\n",
    "                offset = 0  # Start at the beginning\n",
    "                total_records = 100000000  # Example total number of records you wish to download\n",
    "                current_record = 0\n",
    "                while current_record < total_records:\n",
    "                    # Adjust the query to include the limit and offset\n",
    "                    results = client.get(f\"{url}\",query= query+ f\" limit {limit} offset {offset}\")\n",
    "                    \n",
    "                    # Convert to DataFrame and save to CSV\n",
    "                    df = pd.DataFrame.from_records(results)\n",
    "                    df.to_csv(f'{filepath}', index=False)\n",
    "                    \n",
    "                    # Update the offset and current_record count\n",
    "                    offset += limit\n",
    "                    current_record += len(results)\n",
    "\n",
    "                    # Optional: Print progress\n",
    "                    print(f'Downloaded {current_record} of {total_records}')\n",
    "                break\n",
    "            \n",
    "            except ReadTimeout:\n",
    "                # Wait before retrying\n",
    "                time.sleep(retry_wait)\n",
    "                # Reduce the number of retries left\n",
    "                max_retries -= 1\n",
    "                # Increase the wait time for the next retry\n",
    "                retry_wait *= 2\n",
    "        \n",
    "        print(f\"Done downloading {url} from {year}.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Reading from {filepath}...\")\n",
    "\n",
    "\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee245240-2fbb-45b8-9a92-4e2368f62c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_zipcodes(zipcode_datafile):\n",
    "    \"\"\"\n",
    "    Load and clean NYC zipcode data from a shapefile.\n",
    "    Args:\n",
    "    zipcode_datafile (str): The file path to the shapefile.\n",
    "    \n",
    "    Returns:\n",
    "    GeoDataFrame: Cleaned geospatial data frame of NYC zipcodes.\n",
    "    \"\"\"\n",
    "    # Load the shapefile using GeoPandas\n",
    "    gdf = gpd.read_file(zipcode_datafile)\n",
    "    \n",
    "    # Remove unnecessary columns from the dataframe\n",
    "    columns_to_drop = ['BLDGZIP', 'STATE', 'ST_FIPS', 'CTY_FIPS', 'URL', 'SHAPE_AREA', 'SHAPE_LEN']\n",
    "    gdf_cleaned = gdf.drop(columns=columns_to_drop)\n",
    "    gdf.drop_duplicates(subset='ZIPCODE', keep='first', inplace=True)\n",
    "    gdf.dropna(inplace=True)\n",
    "    gdf.drop_duplicates(inplace=True)\n",
    "    # Rename columns for clarity\n",
    "    gdf_cleaned = gdf_cleaned.rename(columns={'PO_NAME': 'City'})\n",
    "    # Set the coordinate reference system to EPSG 4326\n",
    "    gdf_cleaned = gdf_cleaned.to_crs(epsg=4326)\n",
    "    # Normalize column names\n",
    "    gdf_cleaned.columns = [column_name.lower().replace(' ', '_') for column_name in gdf_cleaned.columns]\n",
    "    gdf_cleaned['zipcode']=gdf_cleaned['zipcode'].astype(float).astype(int)\n",
    "    gdf_cleaned['population']=gdf_cleaned['population'].astype(float).astype(int)\n",
    "\n",
    "    return gdf_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eed2a5a9-1027-4c41-bbb5-039c32ce7e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_clean_311_data():\n",
    "    #data downloading\n",
    "    download_nyc_csv_data(2015,\"2015-01-01T00:00:00.000\",\"2015-12-31T23:59:59.999\",\"erm2-nwe9\",'nyc_311_data')\n",
    "    download_nyc_csv_data(2016,\"2016-01-01T00:00:00.000\",\"2016-12-31T23:59:59.999\",\"erm2-nwe9\",'nyc_311_data')\n",
    "    download_nyc_csv_data(2017,\"2017-01-01T00:00:00.000\",\"2017-12-31T23:59:59.999\",\"erm2-nwe9\",'nyc_311_data')\n",
    "    download_nyc_csv_data(2018,\"2018-01-01T00:00:00.000\",\"2018-12-31T23:59:59.999\",\"erm2-nwe9\",'nyc_311_data')\n",
    "    download_nyc_csv_data(2019,\"2019-01-01T00:00:00.000\",\"2019-12-31T23:59:59.999\",\"erm2-nwe9\",'nyc_311_data')\n",
    "    download_nyc_csv_data(2020,\"2020-01-01T00:00:00.000\",\"2020-12-31T23:59:59.999\",\"erm2-nwe9\",'nyc_311_data')\n",
    "    download_nyc_csv_data(2021,\"2021-01-01T00:00:00.000\",\"2021-12-31T23:59:59.999\",\"erm2-nwe9\",'nyc_311_data')\n",
    "    download_nyc_csv_data(2022,\"2022-01-01T00:00:00.000\",\"2022-12-31T23:59:59.999\",\"erm2-nwe9\",'nyc_311_data')\n",
    "    download_nyc_csv_data(2023,\"2023-01-01T00:00:00.000\",\"2015-09-30T23:59:59.999\",\"erm2-nwe9\",'nyc_311_data')\n",
    "\n",
    "    # After downloading all chunks\n",
    "    csv_files = glob.glob('data/nyc_311_data_*.csv')\n",
    "    # Remove unnecessary columns by keeping only the ones you need for each file\n",
    "    dfs=[]\n",
    "    for file in csv_files:\n",
    "        df=pd.read_csv(file)\n",
    "        columns_needed = ['unique_key', 'created_date', 'complaint_type','incident_zip','latitude', 'longitude']  # Replace with actual column names\n",
    "        df = df[columns_needed]\n",
    "        #eliminate duplicate\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        # Remove invalid data points\n",
    "        # This is highly dependent on the context of your data, but as an example:\n",
    "        df.dropna(inplace=True) \n",
    "        # Normalize column names\n",
    "        df.columns = [column_name.lower().replace(' ', '_') for column_name in df.columns]\n",
    "        dfs.append(df) # processed df and append to a list\n",
    "\n",
    "    # Concatenate all DataFrames into one\n",
    "    NYC311_df = pd.concat(dfs,ignore_index=True)\n",
    "    NYC311_df.drop_duplicates(inplace=True)# header duplicate elimination\n",
    "    NYC311_df = NYC311_df.drop_duplicates(subset=['unique_key'])\n",
    "    # Normalize Column Types\n",
    "\n",
    "    # unique_key \n",
    "    NYC311_df['unique_key'] = NYC311_df['unique_key'].astype(int)\n",
    "    # change name into 'id_NYC311'\n",
    "    NYC311_df.rename(columns={'unique_key': 'id_NYC311'}, inplace=True)\n",
    "\n",
    "    #incident zip\n",
    "    #rename from incident_zip to zipcode\n",
    "    NYC311_df.rename(columns={'incident_zip': 'zipcode'}, inplace=True)\n",
    "  \n",
    "    NYC311_df['zipcode']=NYC311_df['zipcode'].astype(float).astype(int)\n",
    "    NYC311_df = NYC311_df[NYC311_df['zipcode'].apply(lambda x: str(x).isdigit() and len(str(x)) == 5)] \n",
    "\n",
    "    #created_date\n",
    "    #rename \"date\"\n",
    "    NYC311_df.rename(columns={'created_date': 'date'}, inplace=True)\n",
    "    # sorting by date\n",
    "    NYC311_df = NYC311_df.sort_values(by='date')\n",
    "    #change date format into yyyy-mm-dd\n",
    "    NYC311_df['date'] = pd.to_datetime(NYC311_df['date']).dt.strftime('%Y-%m-%d')\n",
    "        \n",
    "    # Assuming df is your existing DataFrame with latitude and longitude columns\n",
    "    NYC311_df = gpd.GeoDataFrame(NYC311_df, geometry=gpd.points_from_xy(NYC311_df['longitude'], NYC311_df['latitude']))\n",
    "    NYC311_df.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "\n",
    "    #save the combined DataFrame to a new CSV file\n",
    "    # NYC311_df.to_csv('data/nyc_311_data.csv', index=False)\n",
    "    return NYC311_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39c4b1bc-c841-4b87-8301-1dc2cafeccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_clean_tree_data():\n",
    "    download_nyc_csv_data(2015,\"2015-01-01T00:00:00.000\",\"2015-12-31T23:59:59.999\",\"5rq2-4hqu\",'tree')\n",
    "    tree_df=pd.read_csv('data/tree_2015.csv')\n",
    "    # Remove unnecessary columns by keeping only the ones you need\n",
    "    columns_needed = ['created_at', 'tree_id', 'status','zipcode','health','spc_common', 'latitude', 'longitude']  # Replace with actual column names\n",
    "    tree_df = tree_df[columns_needed]\n",
    "\n",
    "    # Remove invalid data points\n",
    "    # This is highly dependent on the context of your data, but as an example:\n",
    "    tree_df.drop_duplicates(inplace=True)\n",
    "    tree_df = tree_df.drop_duplicates(subset=['tree_id'])\n",
    "    tree_df.dropna(inplace=True)  \n",
    "\n",
    "    # Normalize column names\n",
    "    tree_df.columns = [column_name.lower().replace(' ', '_') for column_name in tree_df.columns]\n",
    "    #created_at\n",
    "    tree_df.rename(columns={'created_at': 'date'}, inplace=True)\n",
    "    tree_df['date'] = pd.to_datetime(tree_df['date']).dt.strftime('%Y-%m-%d')#change date format into yyyy-mm-dd\n",
    "\n",
    "    #zipcode\n",
    "    tree_df['zipcode'] = tree_df['zipcode'].astype(int)\n",
    "    tree_df=tree_df.sort_values('date')\n",
    "\n",
    "    tree_df = gpd.GeoDataFrame(tree_df, geometry=gpd.points_from_xy(tree_df['longitude'], tree_df['latitude']))\n",
    "    tree_df.set_crs(epsg=4326, inplace=True)\n",
    "    return tree_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "323e7af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_and_clean_zillow_data():\n",
    "    \"\"\"\n",
    "    Load and clean Zillow rent data from a CSV file, and transform it to a long format.\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: Cleaned and transformed data frame of Zillow rent data.\n",
    "    \"\"\"\n",
    "    # Load the CSV data using Pandas\n",
    "    zillow_data_path = DATA_DIR / \"zillow_rent_data.csv\"\n",
    "    df = pd.read_csv(zillow_data_path)\n",
    "    \n",
    "    # Keep only necessary columns\n",
    "    columns_to_keep = ['RegionName', 'State', 'City', 'Metro', 'CountyName'] + [col for col in df.columns if '-' in col]\n",
    "    df_cleaned = df[columns_to_keep]\n",
    "    \n",
    "    # Remove rows with a significant number of missing values\n",
    "    df_cleaned = df_cleaned.dropna(thresh=len(df_cleaned.columns)/2, axis=0)\n",
    "\n",
    "    # Filter for rows where the State is 'NY'\n",
    "    df_cleaned = df_cleaned[df_cleaned['State'] == 'NY']\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    df_cleaned = df_cleaned.rename(columns={'RegionName': 'ZipCode'})\n",
    "\n",
    "    # Convert the data from wide format to long format\n",
    "    # Melt the DataFrame to have Date and Rent as separate columns\n",
    "    date_columns = [col for col in df_cleaned.columns if '-' in col]\n",
    "    df_cleaned = df_cleaned.melt(id_vars=['ZipCode', 'State', 'City', 'Metro', 'CountyName'],\n",
    "                                     value_vars=date_columns,\n",
    "                                     var_name='Date',\n",
    "                                     value_name='Rent')\n",
    "    df_cleaned['ZipCode']=df_cleaned['ZipCode'].astype(float).astype(int)\n",
    "    # Normalize column names\n",
    "    df_cleaned.columns = [column_name.lower().replace(' ', '_') for column_name in df_cleaned.columns]\n",
    "    \n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83ab4084",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zillow_data = load_and_clean_zillow_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "345ebc2c-14f1-490c-9857-11f1e332e3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data():\n",
    "    geodf_zipcode_data = load_and_clean_zipcodes(ZIPCODE_DATA_FILE)\n",
    "    geodf_311_data = download_and_clean_311_data()\n",
    "    geodf_tree_data = download_and_clean_tree_data()\n",
    "    df_zillow_data = load_and_clean_zillow_data()\n",
    "    return (\n",
    "        geodf_zipcode_data,\n",
    "        geodf_311_data,\n",
    "        geodf_tree_data,\n",
    "        df_zillow_data\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0716309e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from data/tree_2015.csv...\n"
     ]
    }
   ],
   "source": [
    "geodf_tree_data = download_and_clean_tree_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2768bc8-4130-4298-be28-13d4b250a666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from data/nyc_311_data_2015.csv...\n",
      "Reading from data/nyc_311_data_2016.csv...\n",
      "Reading from data/nyc_311_data_2017.csv...\n",
      "Reading from data/nyc_311_data_2018.csv...\n",
      "Reading from data/nyc_311_data_2019.csv...\n",
      "Reading from data/nyc_311_data_2020.csv...\n",
      "Reading from data/nyc_311_data_2021.csv...\n",
      "Reading from data/nyc_311_data_2022.csv...\n",
      "Reading from data/nyc_311_data_2023.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3q/9w4rbrs12tv6_t2_bscp34qm0000gn/T/ipykernel_6899/883424399.py:18: DtypeWarning: Columns (8,39,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv(file)\n",
      "/var/folders/3q/9w4rbrs12tv6_t2_bscp34qm0000gn/T/ipykernel_6899/883424399.py:18: DtypeWarning: Columns (8,38,39,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv(file)\n",
      "/var/folders/3q/9w4rbrs12tv6_t2_bscp34qm0000gn/T/ipykernel_6899/883424399.py:18: DtypeWarning: Columns (8,33,34,35,36,37,39,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv(file)\n",
      "/var/folders/3q/9w4rbrs12tv6_t2_bscp34qm0000gn/T/ipykernel_6899/883424399.py:18: DtypeWarning: Columns (8,34,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv(file)\n",
      "/var/folders/3q/9w4rbrs12tv6_t2_bscp34qm0000gn/T/ipykernel_6899/883424399.py:18: DtypeWarning: Columns (38,39,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv(file)\n",
      "/var/folders/3q/9w4rbrs12tv6_t2_bscp34qm0000gn/T/ipykernel_6899/883424399.py:18: DtypeWarning: Columns (39,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv(file)\n",
      "/var/folders/3q/9w4rbrs12tv6_t2_bscp34qm0000gn/T/ipykernel_6899/883424399.py:18: DtypeWarning: Columns (8,38,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv(file)\n",
      "/var/folders/3q/9w4rbrs12tv6_t2_bscp34qm0000gn/T/ipykernel_6899/883424399.py:18: DtypeWarning: Columns (8,39,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv(file)\n",
      "/var/folders/3q/9w4rbrs12tv6_t2_bscp34qm0000gn/T/ipykernel_6899/883424399.py:18: DtypeWarning: Columns (8,39,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from data/tree_2015.csv...\n"
     ]
    }
   ],
   "source": [
    "geodf_zipcode_data, geodf_311_data, geodf_tree_data, df_zillow_data = load_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23ad8bbc-bf91-457e-97db-a945fabeee29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 263 entries, 0 to 262\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   zipcode     263 non-null    int64   \n",
      " 1   city        263 non-null    object  \n",
      " 2   population  263 non-null    int64   \n",
      " 3   area        263 non-null    float64 \n",
      " 4   county      263 non-null    object  \n",
      " 5   geometry    263 non-null    geometry\n",
      "dtypes: float64(1), geometry(1), int64(2), object(2)\n",
      "memory usage: 12.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Show basic info about each dataframe\n",
    "geodf_zipcode_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec68f4be-f365-46c1-91a1-ab75deb75ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zipcode</th>\n",
       "      <th>city</th>\n",
       "      <th>population</th>\n",
       "      <th>area</th>\n",
       "      <th>county</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11436</td>\n",
       "      <td>Jamaica</td>\n",
       "      <td>18681</td>\n",
       "      <td>2.269930e+07</td>\n",
       "      <td>Queens</td>\n",
       "      <td>POLYGON ((-73.80585 40.68291, -73.80569 40.682...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11213</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>62426</td>\n",
       "      <td>2.963100e+07</td>\n",
       "      <td>Kings</td>\n",
       "      <td>POLYGON ((-73.93740 40.67973, -73.93487 40.679...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11212</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>83866</td>\n",
       "      <td>4.197210e+07</td>\n",
       "      <td>Kings</td>\n",
       "      <td>POLYGON ((-73.90294 40.67084, -73.90223 40.668...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11225</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>56527</td>\n",
       "      <td>2.369863e+07</td>\n",
       "      <td>Kings</td>\n",
       "      <td>POLYGON ((-73.95797 40.67066, -73.95576 40.670...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11218</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>72280</td>\n",
       "      <td>3.686880e+07</td>\n",
       "      <td>Kings</td>\n",
       "      <td>POLYGON ((-73.97208 40.65060, -73.97192 40.650...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   zipcode      city  population          area  county  \\\n",
       "0    11436   Jamaica       18681  2.269930e+07  Queens   \n",
       "1    11213  Brooklyn       62426  2.963100e+07   Kings   \n",
       "2    11212  Brooklyn       83866  4.197210e+07   Kings   \n",
       "3    11225  Brooklyn       56527  2.369863e+07   Kings   \n",
       "4    11218  Brooklyn       72280  3.686880e+07   Kings   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((-73.80585 40.68291, -73.80569 40.682...  \n",
       "1  POLYGON ((-73.93740 40.67973, -73.93487 40.679...  \n",
       "2  POLYGON ((-73.90294 40.67084, -73.90223 40.668...  \n",
       "3  POLYGON ((-73.95797 40.67066, -73.95576 40.670...  \n",
       "4  POLYGON ((-73.97208 40.65060, -73.97192 40.650...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show first 5 entries about each dataframe\n",
    "geodf_zipcode_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a803b68-2f07-44b8-8b24-d4f16c9e03fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "Int64Index: 23030426 entries, 291587 to 16420015\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Dtype   \n",
      "---  ------          -----   \n",
      " 0   id_NYC311       int64   \n",
      " 1   date            object  \n",
      " 2   complaint_type  object  \n",
      " 3   zipcode         int64   \n",
      " 4   latitude        float64 \n",
      " 5   longitude       float64 \n",
      " 6   geometry        geometry\n",
      "dtypes: float64(2), geometry(1), int64(2), object(2)\n",
      "memory usage: 1.4+ GB\n"
     ]
    }
   ],
   "source": [
    "geodf_311_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14705df9-ea77-4d57-ac8e-1845f80a216d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_NYC311</th>\n",
       "      <th>date</th>\n",
       "      <th>complaint_type</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>291587</th>\n",
       "      <td>29616011</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>HEAT/HOT WATER</td>\n",
       "      <td>11207</td>\n",
       "      <td>40.667093</td>\n",
       "      <td>-73.891719</td>\n",
       "      <td>POINT (-73.89172 40.66709)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291738</th>\n",
       "      <td>29615514</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>HEAT/HOT WATER</td>\n",
       "      <td>10034</td>\n",
       "      <td>40.868366</td>\n",
       "      <td>-73.916422</td>\n",
       "      <td>POINT (-73.91642 40.86837)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291739</th>\n",
       "      <td>29615513</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>HEAT/HOT WATER</td>\n",
       "      <td>11377</td>\n",
       "      <td>40.744999</td>\n",
       "      <td>-73.892968</td>\n",
       "      <td>POINT (-73.89297 40.74500)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291740</th>\n",
       "      <td>29615512</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>HEAT/HOT WATER</td>\n",
       "      <td>10472</td>\n",
       "      <td>40.833156</td>\n",
       "      <td>-73.870540</td>\n",
       "      <td>POINT (-73.87054 40.83316)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291741</th>\n",
       "      <td>29615511</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>HEAT/HOT WATER</td>\n",
       "      <td>10024</td>\n",
       "      <td>40.787862</td>\n",
       "      <td>-73.976899</td>\n",
       "      <td>POINT (-73.97690 40.78786)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_NYC311        date  complaint_type  zipcode   latitude  longitude  \\\n",
       "291587   29616011  2015-01-01  HEAT/HOT WATER    11207  40.667093 -73.891719   \n",
       "291738   29615514  2015-01-01  HEAT/HOT WATER    10034  40.868366 -73.916422   \n",
       "291739   29615513  2015-01-01  HEAT/HOT WATER    11377  40.744999 -73.892968   \n",
       "291740   29615512  2015-01-01  HEAT/HOT WATER    10472  40.833156 -73.870540   \n",
       "291741   29615511  2015-01-01  HEAT/HOT WATER    10024  40.787862 -73.976899   \n",
       "\n",
       "                          geometry  \n",
       "291587  POINT (-73.89172 40.66709)  \n",
       "291738  POINT (-73.91642 40.86837)  \n",
       "291739  POINT (-73.89297 40.74500)  \n",
       "291740  POINT (-73.87054 40.83316)  \n",
       "291741  POINT (-73.97690 40.78786)  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geodf_311_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6006cd2-3a00-4660-8d2a-a660b9bfd91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "Int64Index: 189969 entries, 13800 to 196344\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count   Dtype   \n",
      "---  ------      --------------   -----   \n",
      " 0   date        189969 non-null  object  \n",
      " 1   tree_id     189969 non-null  int64   \n",
      " 2   status      189969 non-null  object  \n",
      " 3   zipcode     189969 non-null  int64   \n",
      " 4   health      189969 non-null  object  \n",
      " 5   spc_common  189969 non-null  object  \n",
      " 6   latitude    189969 non-null  float64 \n",
      " 7   longitude   189969 non-null  float64 \n",
      " 8   geometry    189969 non-null  geometry\n",
      "dtypes: float64(2), geometry(1), int64(2), object(4)\n",
      "memory usage: 14.5+ MB\n"
     ]
    }
   ],
   "source": [
    "geodf_tree_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07f880ef-c5fc-4159-8174-21ccd44f492d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tree_id</th>\n",
       "      <th>status</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>health</th>\n",
       "      <th>spc_common</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13800</th>\n",
       "      <td>2015-05-19</td>\n",
       "      <td>347</td>\n",
       "      <td>Alive</td>\n",
       "      <td>10459</td>\n",
       "      <td>Fair</td>\n",
       "      <td>American hornbeam</td>\n",
       "      <td>40.821445</td>\n",
       "      <td>-73.892916</td>\n",
       "      <td>POINT (-73.89292 40.82144)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45386</th>\n",
       "      <td>2015-05-19</td>\n",
       "      <td>317</td>\n",
       "      <td>Alive</td>\n",
       "      <td>10459</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Amur maackia</td>\n",
       "      <td>40.825308</td>\n",
       "      <td>-73.897495</td>\n",
       "      <td>POINT (-73.89750 40.82531)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>2015-05-19</td>\n",
       "      <td>306</td>\n",
       "      <td>Alive</td>\n",
       "      <td>10459</td>\n",
       "      <td>Good</td>\n",
       "      <td>Siberian elm</td>\n",
       "      <td>40.823933</td>\n",
       "      <td>-73.897177</td>\n",
       "      <td>POINT (-73.89718 40.82393)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22732</th>\n",
       "      <td>2015-05-19</td>\n",
       "      <td>9</td>\n",
       "      <td>Alive</td>\n",
       "      <td>10474</td>\n",
       "      <td>Poor</td>\n",
       "      <td>silver birch</td>\n",
       "      <td>40.814107</td>\n",
       "      <td>-73.889021</td>\n",
       "      <td>POINT (-73.88902 40.81411)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4301</th>\n",
       "      <td>2015-05-19</td>\n",
       "      <td>307</td>\n",
       "      <td>Alive</td>\n",
       "      <td>10459</td>\n",
       "      <td>Good</td>\n",
       "      <td>Siberian elm</td>\n",
       "      <td>40.824059</td>\n",
       "      <td>-73.897260</td>\n",
       "      <td>POINT (-73.89726 40.82406)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  tree_id status  zipcode health         spc_common  \\\n",
       "13800  2015-05-19      347  Alive    10459   Fair  American hornbeam   \n",
       "45386  2015-05-19      317  Alive    10459   Fair       Amur maackia   \n",
       "1890   2015-05-19      306  Alive    10459   Good       Siberian elm   \n",
       "22732  2015-05-19        9  Alive    10474   Poor       silver birch   \n",
       "4301   2015-05-19      307  Alive    10459   Good       Siberian elm   \n",
       "\n",
       "        latitude  longitude                    geometry  \n",
       "13800  40.821445 -73.892916  POINT (-73.89292 40.82144)  \n",
       "45386  40.825308 -73.897495  POINT (-73.89750 40.82531)  \n",
       "1890   40.823933 -73.897177  POINT (-73.89718 40.82393)  \n",
       "22732  40.814107 -73.889021  POINT (-73.88902 40.81411)  \n",
       "4301   40.824059 -73.897260  POINT (-73.89726 40.82406)  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geodf_tree_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59724f74-5f1e-435c-b843-f381a875dd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9660 entries, 0 to 9659\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   zipcode     9660 non-null   int64  \n",
      " 1   state       9660 non-null   object \n",
      " 2   city        9660 non-null   object \n",
      " 3   metro       9660 non-null   object \n",
      " 4   countyname  9660 non-null   object \n",
      " 5   date        9660 non-null   object \n",
      " 6   rent        8716 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(5)\n",
      "memory usage: 528.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_zillow_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e29ae5d9-9768-4590-a2f2-dd63b07dd712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zipcode</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>metro</th>\n",
       "      <th>countyname</th>\n",
       "      <th>date</th>\n",
       "      <th>rent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11385</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York-Newark-Jersey City, NY-NJ-PA</td>\n",
       "      <td>Queens County</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10467</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York-Newark-Jersey City, NY-NJ-PA</td>\n",
       "      <td>Bronx County</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11226</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York-Newark-Jersey City, NY-NJ-PA</td>\n",
       "      <td>Kings County</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>1944.609891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11207</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York-Newark-Jersey City, NY-NJ-PA</td>\n",
       "      <td>Kings County</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10025</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York-Newark-Jersey City, NY-NJ-PA</td>\n",
       "      <td>New York County</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>3068.951823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   zipcode state      city                                  metro  \\\n",
       "0    11385    NY  New York  New York-Newark-Jersey City, NY-NJ-PA   \n",
       "1    10467    NY  New York  New York-Newark-Jersey City, NY-NJ-PA   \n",
       "2    11226    NY  New York  New York-Newark-Jersey City, NY-NJ-PA   \n",
       "3    11207    NY  New York  New York-Newark-Jersey City, NY-NJ-PA   \n",
       "4    10025    NY  New York  New York-Newark-Jersey City, NY-NJ-PA   \n",
       "\n",
       "        countyname        date         rent  \n",
       "0    Queens County  2015-01-31          NaN  \n",
       "1     Bronx County  2015-01-31          NaN  \n",
       "2     Kings County  2015-01-31  1944.609891  \n",
       "3     Kings County  2015-01-31          NaN  \n",
       "4  New York County  2015-01-31  3068.951823  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zillow_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e685942c-26dc-40db-84c2-a71aa3340806",
   "metadata": {},
   "source": [
    "## Part 2: Storing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527a251c-f337-4b24-bb41-96ee4621a9bd",
   "metadata": {},
   "source": [
    "### Creating Tables\n",
    "\n",
    "\n",
    "These are just a couple of options to creating your tables; you can use one or the other, a different method, or a combination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232a2d89-b276-4d44-a0ef-3631eb686e84",
   "metadata": {},
   "source": [
    "#### Option 2: SQLAlchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d41c42e1-4ad4-4c43-a2ba-1dbcac1de557",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base = declarative_base()\n",
    "\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Float, Date, MetaData, Table\n",
    "from geoalchemy2 import Geometry\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "\n",
    "class ZipcodeArea(Base):\n",
    "    __tablename__ = 'zipcode_areas'  # Replace with your actual table name\n",
    "    # Assuming 'zipcode' is a unique identifier for each row\n",
    "    zipcode = Column(Integer, primary_key=True)\n",
    "    city = Column(String)\n",
    "    population = Column(Integer)\n",
    "    area = Column(Float)\n",
    "    county = Column(String)\n",
    "    geometry = Column(Geometry('POLYGON', srid=4326))  # Adjust the geometry type if needed\n",
    "\n",
    "class NYC311Complaints(Base):\n",
    "    __tablename__ = 'nyc311_complaints'\n",
    "    id_NYC311 = Column(Integer, primary_key=True)\n",
    "    date = Column(Date)\n",
    "    complaint_type = Column(String)\n",
    "    zipcode = Column(Integer)\n",
    "    latitude = Column(Float)\n",
    "    longitude = Column(Float)\n",
    "    geometry = Column(Geometry(geometry_type='POINT', srid=4326))\n",
    "\n",
    "class Tree(Base):\n",
    "    __tablename__ = 'trees'\n",
    "    tree_id = Column(Integer, primary_key=True)\n",
    "    date = Column(Date)\n",
    "    status = Column(String)\n",
    "    zipcode = Column(Integer)\n",
    "    health = Column(String)\n",
    "    spc_common = Column(String)\n",
    "    latitude = Column(Float)\n",
    "    longitude = Column(Float)\n",
    "    geometry = Column(Geometry(geometry_type='POINT', srid=4326))\n",
    "\n",
    "class Rent(Base):\n",
    "    __tablename__ = 'rents'\n",
    "    id=Column(Integer, primary_key=True)\n",
    "    zipcode = Column(Integer)\n",
    "    state = Column(String)\n",
    "    city = Column(String)\n",
    "    metro = Column(String)\n",
    "    countyname = Column(String)\n",
    "    date = Column(Date)\n",
    "    rent = Column(Float)\n",
    "\n",
    "engine = create_engine(DB_URL)\n",
    "Base.metadata.create_all(engine)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e88a50c-9528-4a5c-9a52-b96781ee8985",
   "metadata": {},
   "source": [
    "### Add Data to Database\n",
    "\n",
    "These are just a couple of options to write data to your tables; you can use one or the other, a different method, or a combination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9207cec5",
   "metadata": {},
   "source": [
    "Add ZipCode Data to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8c50667",
   "metadata": {},
   "outputs": [],
   "source": [
    "Session = db.orm.sessionmaker(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6126be5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3q/9w4rbrs12tv6_t2_bscp34qm0000gn/T/ipykernel_6899/1732785940.py:4: UserWarning: Geometry column does not contain geometry.\n",
      "  geodf_zipcode_data['geometry'] = geodf_zipcode_data['geometry'].apply(lambda geom: geom.wkt)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from shapely import wkt\n",
    "from sqlalchemy.dialects.postgresql import insert\n",
    "\n",
    "geodf_zipcode_data['geometry'] = geodf_zipcode_data['geometry'].apply(lambda geom: geom.wkt)\n",
    "for index, row in geodf_zipcode_data.iterrows():\n",
    "    insert_stmt = insert(ZipcodeArea).values(\n",
    "        zipcode=row['zipcode'],\n",
    "        city=row['city'],\n",
    "        population=row['population'],\n",
    "        area=row['area'],\n",
    "        county=row['county'],\n",
    "        geometry=row['geometry']\n",
    "    )\n",
    "    on_conflict_stmt = insert_stmt.on_conflict_do_update(\n",
    "        index_elements=['zipcode'],  # Unique constraint or column(s) causing conflict\n",
    "        set_=dict(\n",
    "            city=row['city'],\n",
    "            population=row['population'],\n",
    "            area=row['area'],\n",
    "            county=row['county'],\n",
    "            geometry=row['geometry']\n",
    "        )\n",
    "    )\n",
    "    session.execute(on_conflict_stmt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3dc0d934",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f6e404",
   "metadata": {},
   "source": [
    "Add NYC 311 Complaint Data to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dce0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.dialects.postgresql import insert\n",
    "# Convert geometry column to WKT format\n",
    "geodf_311_data['geometry'] = geodf_311_data['geometry'].apply(lambda geom: geom.wkt)\n",
    "\n",
    "def insert_batch(session, model, data, batch_size=200000):\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        batch = data.iloc[i:i+batch_size].to_dict(orient='records')\n",
    "\n",
    "        for record in batch:\n",
    "            stmt = insert(model).values(record)\n",
    "            do_nothing_stmt = stmt.on_conflict_do_nothing(index_elements=['id_NYC311'])\n",
    "            session.execute(do_nothing_stmt)\n",
    "\n",
    "        session.commit()\n",
    "\n",
    "# Insert data in batches\n",
    "insert_batch(session, NYC311Complaints, geodf_311_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d792f6eb",
   "metadata": {},
   "source": [
    "Add Tree Data to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77174d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3q/9w4rbrs12tv6_t2_bscp34qm0000gn/T/ipykernel_6899/3861239950.py:1: UserWarning: Geometry column does not contain geometry.\n",
      "  geodf_tree_data['geometry'] = geodf_tree_data['geometry'].apply(lambda geom: geom.wkt)\n"
     ]
    }
   ],
   "source": [
    "geodf_tree_data['geometry'] = geodf_tree_data['geometry'].apply(lambda geom: geom.wkt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ba74275",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for index, row in geodf_tree_data.iterrows():\n",
    "    insert_stmt = insert(Tree).values(\n",
    "        tree_id=row['tree_id'],\n",
    "        date=row['date'],\n",
    "        status=row['status'],\n",
    "        zipcode=row['zipcode'],\n",
    "        health=row['health'],\n",
    "        spc_common=row['spc_common'],\n",
    "        latitude=row['latitude'],\n",
    "        longitude=row['longitude'],\n",
    "        geometry=row['geometry']\n",
    "    )\n",
    "\n",
    "    on_conflict_stmt = insert_stmt.on_conflict_do_update(\n",
    "        index_elements=['tree_id'],  # Assuming tree_id is the unique identifier\n",
    "        set_=dict(\n",
    "            date=row['date'],\n",
    "            status=row['status'],\n",
    "            zipcode=row['zipcode'],\n",
    "            health=row['health'],\n",
    "            spc_common=row['spc_common'],\n",
    "            latitude=row['latitude'],\n",
    "            longitude=row['longitude'],\n",
    "            geometry=row['geometry']\n",
    "        )\n",
    "    )\n",
    "\n",
    "    session.execute(on_conflict_stmt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ea33daf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a340ea",
   "metadata": {},
   "source": [
    "Add Zillow Rent Data to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e5181fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each row in the DataFrame for Zillow rent data\n",
    "for index, row in df_zillow_data.iterrows():\n",
    "    # Create a ZillowRent object for each row (assuming ZillowRent is the model class)\n",
    "    rent = Rent(\n",
    "        zipcode=row['zipcode'],\n",
    "        state=row['state'],\n",
    "        city=row['city'],\n",
    "        metro=row['metro'],\n",
    "        countyname=row['countyname'],\n",
    "        date=row['date'],\n",
    "        rent=row['rent']\n",
    "    )\n",
    "    # Add each ZillowRent object to the session\n",
    "    session.add(rent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b121ea57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alter_statement = text( \"ALTER TABLE rents ADD COLUMN id SERIAL PRIMARY KEY;\")\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(\"ALTER TABLE rents DROP CONSTRAINT rents_pkey;\")\n",
    "    connection.execute(alter_statement)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e454a2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commit the session to save all added objects to the database\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb63b553-0c64-4da8-9fc7-41555d89d853",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac7e12b-e251-4f08-8dc5-601db30c2089",
   "metadata": {},
   "source": [
    "### Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ce8548-4aba-4bf9-992c-dedd0f249db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to write the queries to file\n",
    "def write_query_to_file(query, outfile):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5b2adbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11226, 49279)\n",
      "(10467, 47364)\n",
      "(10468, 44045)\n",
      "(10452, 43858)\n",
      "(11385, 43587)\n",
      "(10457, 41497)\n",
      "(10458, 41152)\n",
      "(11207, 39922)\n",
      "(10456, 39756)\n",
      "(11201, 39230)\n",
      "(10453, 38065)\n",
      "(11208, 36494)\n",
      "(10031, 33798)\n",
      "(11221, 33073)\n",
      "(10466, 32515)\n",
      "(10032, 31973)\n",
      "(10025, 30935)\n",
      "(10462, 30720)\n",
      "(11238, 30114)\n",
      "(11230, 29440)\n",
      "(11368, 29235)\n",
      "(11220, 28845)\n",
      "(10019, 28113)\n",
      "(11216, 28068)\n",
      "(11225, 28030)\n",
      "(11235, 27685)\n",
      "(11212, 27233)\n",
      "(10460, 26955)\n",
      "(10463, 26954)\n",
      "(10023, 26805)\n",
      "(11203, 26749)\n",
      "(11214, 26632)\n",
      "(11377, 26222)\n",
      "(10027, 25785)\n",
      "(11101, 25752)\n",
      "(11213, 25733)\n",
      "(10002, 25553)\n",
      "(11211, 25467)\n",
      "(11206, 25334)\n",
      "(10472, 25334)\n",
      "(11234, 25282)\n",
      "(11222, 25262)\n",
      "(11209, 25145)\n",
      "(11215, 25127)\n",
      "(11218, 24989)\n",
      "(11233, 24875)\n",
      "(11223, 24058)\n",
      "(11373, 23929)\n",
      "(10033, 23654)\n",
      "(11237, 23320)\n",
      "(11229, 22655)\n",
      "(11236, 22375)\n",
      "(10461, 22256)\n",
      "(10034, 22248)\n",
      "(10011, 22088)\n",
      "(11204, 21658)\n",
      "(10003, 21570)\n",
      "(10026, 21260)\n",
      "(10469, 21187)\n",
      "(10009, 20997)\n",
      "(11210, 20924)\n",
      "(10029, 20808)\n",
      "(10451, 20695)\n",
      "(10036, 20683)\n",
      "(11372, 20405)\n",
      "(10459, 20278)\n",
      "(11217, 20230)\n",
      "(10040, 19833)\n",
      "(10314, 19701)\n",
      "(11231, 19555)\n",
      "(11432, 19522)\n",
      "(11419, 19477)\n",
      "(11420, 19275)\n",
      "(11378, 19032)\n",
      "(11375, 18921)\n",
      "(11219, 18827)\n",
      "(11355, 18702)\n",
      "(10455, 18392)\n",
      "(11366, 18382)\n",
      "(10035, 18266)\n",
      "(10030, 18015)\n",
      "(10016, 17075)\n",
      "(11421, 17042)\n",
      "(11205, 17008)\n",
      "(10312, 16709)\n",
      "(11434, 16612)\n",
      "(11435, 16545)\n",
      "(11414, 16135)\n",
      "(10024, 16041)\n",
      "(11691, 15841)\n",
      "(10473, 15546)\n",
      "(10306, 15538)\n",
      "(11103, 15300)\n",
      "(11106, 14936)\n",
      "(11379, 14586)\n",
      "(11224, 14417)\n",
      "(11433, 14266)\n",
      "(11105, 14247)\n",
      "(10465, 14021)\n",
      "(10028, 13965)\n",
      "(11354, 13895)\n",
      "(10301, 13619)\n",
      "(10454, 13603)\n",
      "(10014, 13360)\n",
      "(10001, 13126)\n",
      "(11249, 12938)\n",
      "(11357, 12708)\n",
      "(10304, 12680)\n",
      "(11369, 12563)\n",
      "(10013, 12336)\n",
      "(11232, 12241)\n",
      "(11102, 12219)\n",
      "(11374, 12173)\n",
      "(10039, 11956)\n",
      "(11417, 11914)\n",
      "(11365, 11857)\n",
      "(10128, 11850)\n",
      "(11228, 11833)\n",
      "(11418, 11663)\n",
      "(10012, 11510)\n",
      "(11239, 11020)\n",
      "(10305, 10748)\n",
      "(11358, 10506)\n",
      "(11413, 10489)\n",
      "(11412, 10359)\n",
      "(10309, 9866)\n",
      "(11356, 9836)\n",
      "(10022, 9686)\n",
      "(11104, 9599)\n",
      "(10021, 9587)\n",
      "(10470, 8933)\n",
      "(11361, 8928)\n",
      "(11367, 8742)\n",
      "(11416, 8467)\n",
      "(11423, 8306)\n",
      "(11694, 8252)\n",
      "(10065, 8041)\n",
      "(10037, 7939)\n",
      "(10010, 7907)\n",
      "(11422, 7816)\n",
      "(10018, 7593)\n",
      "(10471, 7550)\n",
      "(11436, 7514)\n",
      "(11370, 7235)\n",
      "(11364, 6954)\n",
      "(10474, 6781)\n",
      "(10308, 6713)\n",
      "(10017, 6680)\n",
      "(10310, 6679)\n",
      "(10038, 6675)\n",
      "(10303, 6609)\n",
      "(10302, 6410)\n",
      "(11429, 6025)\n",
      "(10075, 5703)\n",
      "(11415, 5633)\n",
      "(11692, 5595)\n",
      "(11411, 5513)\n",
      "(11428, 5359)\n",
      "(11427, 4951)\n",
      "(11693, 4200)\n",
      "(11426, 4071)\n",
      "(10007, 4024)\n",
      "(11360, 3805)\n",
      "(10307, 3735)\n",
      "(10475, 3734)\n",
      "(11362, 3191)\n",
      "(11430, 3064)\n",
      "(10464, 2534)\n",
      "(10004, 2487)\n",
      "(11004, 2360)\n",
      "(10005, 2082)\n",
      "(11363, 1865)\n",
      "(11109, 1837)\n",
      "(10006, 1578)\n",
      "(10044, 1040)\n",
      "(11001, 812)\n",
      "(10282, 742)\n",
      "(10000, 689)\n",
      "(11040, 642)\n",
      "(10069, 593)\n",
      "(10280, 555)\n",
      "(10020, 432)\n",
      "(10169, 412)\n",
      "(10121, 286)\n",
      "(10107, 228)\n",
      "(10278, 204)\n",
      "(10105, 164)\n",
      "(10153, 153)\n",
      "(11359, 146)\n",
      "(11697, 111)\n",
      "(10172, 101)\n",
      "(10151, 83)\n",
      "(10103, 81)\n",
      "(10281, 68)\n",
      "(10168, 60)\n",
      "(10118, 52)\n",
      "(12345, 51)\n",
      "(11005, 50)\n",
      "(10120, 48)\n",
      "(10106, 45)\n",
      "(11251, 41)\n",
      "(10162, 39)\n",
      "(10119, 35)\n",
      "(10271, 34)\n",
      "(10041, 33)\n",
      "(10112, 28)\n",
      "(10165, 27)\n",
      "(10045, 27)\n",
      "(10171, 24)\n",
      "(10110, 24)\n",
      "(10170, 24)\n",
      "(10048, 23)\n",
      "(10154, 22)\n",
      "(10178, 22)\n",
      "(10158, 21)\n",
      "(11371, 20)\n",
      "(11241, 18)\n",
      "(10123, 17)\n",
      "(10179, 16)\n",
      "(10174, 16)\n",
      "(10279, 15)\n",
      "(10177, 13)\n",
      "(10115, 12)\n",
      "(10111, 12)\n",
      "(11695, 11)\n",
      "(11242, 11)\n",
      "(10176, 8)\n",
      "(10152, 7)\n",
      "(10166, 7)\n",
      "(10173, 5)\n",
      "(10803, 4)\n",
      "(10122, 4)\n",
      "(10155, 4)\n",
      "(10167, 4)\n",
      "(10055, 2)\n",
      "(10175, 1)\n",
      "(10080, 1)\n",
      "(10550, 1)\n",
      "(29601, 1)\n",
      "(33496, 1)\n",
      "(45040, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sqlalchemy.sql import text\n",
    "\n",
    "# Define the directory where query files will be saved\n",
    "# Creates the directory if it does not exist\n",
    "QUERY_DIR = pathlib.Path(\"queries\")\n",
    "QUERY_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Define the SQL query for Query 1\n",
    "# This query finds the number of 311 complaints per zip code \n",
    "# between 2022-10-01 and 2023-09-30 and orders them in descending order\n",
    "QUERY_1 = \"\"\"\n",
    "SELECT zipcode, COUNT(*) AS complaint_count\n",
    "FROM nyc311_complaints\n",
    "WHERE date BETWEEN '2022-10-01' AND '2023-09-30'\n",
    "GROUP BY zipcode\n",
    "ORDER BY complaint_count DESC;\n",
    "\"\"\"\n",
    "\n",
    "# Function to write the SQL query to a file\n",
    "def write_query_to_file(query, outfile):\n",
    "    with open(outfile, 'w') as file:\n",
    "        file.write(query)\n",
    "\n",
    "# File path for saving the query\n",
    "QUERY_1_FILENAME = QUERY_DIR / \"complaints_per_zipcode.sql\"\n",
    "\n",
    "# Execute the query and print the results\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(QUERY_1))\n",
    "    for row in result:\n",
    "        print(row)\n",
    "\n",
    "# Write the query to a file\n",
    "write_query_to_file(QUERY_1, QUERY_1_FILENAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f63b95f",
   "metadata": {},
   "source": [
    "### Query 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "682b9035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10309, 7839)\n",
      "(10312, 6946)\n",
      "(10469, 4703)\n",
      "(11230, 4684)\n",
      "(10314, 3964)\n",
      "(10306, 3767)\n",
      "(10465, 3461)\n",
      "(11229, 3395)\n",
      "(11375, 3324)\n",
      "(10461, 3315)\n"
     ]
    }
   ],
   "source": [
    "# Query 2: Finding the top 10 zip codes with the most trees\n",
    "# This query aims to identify which 10 zip codes have the highest number of trees\n",
    "\n",
    "QUERY_2 = \"\"\"\n",
    "SELECT zipcode, COUNT(*) AS tree_count\n",
    "FROM trees\n",
    "GROUP BY zipcode\n",
    "ORDER BY tree_count DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "# File path for saving the query\n",
    "QUERY_2_FILENAME = QUERY_DIR / \"top_10_zipcodes_by_trees.sql\"\n",
    "\n",
    "# Execute the query and print the results\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(QUERY_2))\n",
    "    for row in result:\n",
    "        print(row)\n",
    "\n",
    "# Write the query to a file\n",
    "write_query_to_file(QUERY_2, QUERY_2_FILENAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7e33e5",
   "metadata": {},
   "source": [
    "### Query 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f11a0c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10462, Decimal('2001.59'))\n",
      "(10467, Decimal('2353.69'))\n",
      "(11210, Decimal('2707.10'))\n",
      "(11215, Decimal('3575.65'))\n",
      "(11218, Decimal('2756.59'))\n",
      "(11229, Decimal('2680.57'))\n",
      "(11230, Decimal('2657.04'))\n",
      "(11235, Decimal('2457.56'))\n",
      "(11355, Decimal('2121.97'))\n",
      "(11375, Decimal('2743.40'))\n"
     ]
    }
   ],
   "source": [
    "# Query 3: Calculating average rent in the areas with the most trees for August 2023\n",
    "# This query identifies the average rent by zip code for the top 10 zip codes with the most trees, \n",
    "# specifically for the month of August 2023\n",
    "\n",
    "QUERY_3 = \"\"\"\n",
    "WITH TopTreeZipCodes AS (\n",
    "    SELECT r.zipcode\n",
    "    FROM trees\n",
    "    JOIN rents r ON trees.zipcode = r.zipcode\n",
    "    GROUP BY r.zipcode\n",
    "    ORDER BY COUNT(*) DESC\n",
    "    LIMIT 10\n",
    ")\n",
    "SELECT ttz.zipcode, ROUND(CAST(AVG(r.rent) AS numeric), 2) AS average_rent\n",
    "FROM TopTreeZipCodes ttz\n",
    "JOIN rents r ON ttz.zipcode = r.zipcode\n",
    "WHERE r.date BETWEEN '2023-08-01' AND '2023-08-31'\n",
    "GROUP BY ttz.zipcode\n",
    "ORDER BY COUNT(*) DESC;\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# File path for saving the query\n",
    "QUERY_3_FILENAME = QUERY_DIR / \"average_rent_in_green_areas.sql\"\n",
    "\n",
    "# Execute the query and print the results\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(QUERY_3))\n",
    "    for row in result:\n",
    "        print(row)\n",
    "\n",
    "# Write the query to a file\n",
    "write_query_to_file(QUERY_3, QUERY_3_FILENAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5c0bbb",
   "metadata": {},
   "source": [
    "### Query 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29adf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 4: Correlation between area's rent, tree count, and number of 311 complaints\n",
    "# This query finds the 5 zip codes with the lowest and highest average rent for January 2023,\n",
    "# along with the tree count and complaint count for each zip code\n",
    "\n",
    "QUERY_4 = \"\"\"\n",
    "WITH RentRanking AS (\n",
    "    SELECT zipcode, ROUND(AVG(rent), 2) AS average_rent,\n",
    "    RANK() OVER (ORDER BY AVG(rent)) AS rent_rank\n",
    "    FROM zillow_rent\n",
    "    WHERE date BETWEEN '2023-01-01' AND '2023-01-31'\n",
    "    GROUP BY zipcode\n",
    ")\n",
    "SELECT rr.zipcode, rr.average_rent, \n",
    "       (SELECT COUNT(*) FROM tree_data WHERE zipcode = rr.zipcode) AS tree_count,\n",
    "       (SELECT COUNT(*) FROM nyc311_complaints WHERE zipcode = rr.zipcode AND date BETWEEN '2023-01-01' AND '2023-01-31') AS complaint_count\n",
    "FROM RentRanking rr\n",
    "WHERE rr.rent_rank <= 5 OR rr.rent_rank >= (SELECT MAX(rent_rank) - 4 FROM RentRanking)\n",
    "ORDER BY rr.average_rent;\n",
    "\"\"\"\n",
    "\n",
    "# File path for saving the query\n",
    "QUERY_4_FILENAME = QUERY_DIR / \"rent_tree_complaint_correlation.sql\"\n",
    "\n",
    "# Execute the query and print the results\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(QUERY_4))\n",
    "    for row in result:\n",
    "        print(row)\n",
    "\n",
    "# Write the query to a file\n",
    "write_query_to_file(QUERY_4, QUERY_4_FILENAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd939d04",
   "metadata": {},
   "source": [
    "### Query 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eacaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 5: Identifying areas with the most greenery using spatial join\n",
    "# This query rewrites Query 2 to include a spatial join between the trees table and the zipcodes table\n",
    "# to determine which trees are located within the boundary of a zipcode\n",
    "\n",
    "QUERY_5 = \"\"\"\n",
    "WITH TreeCount AS (\n",
    "    SELECT z.zipcode, COUNT(t.id) AS tree_count\n",
    "    FROM zipcodes z\n",
    "    JOIN tree_data t ON ST_Within(t.geom, z.geom)\n",
    "    GROUP BY z.zipcode\n",
    ")\n",
    "SELECT zipcode, tree_count\n",
    "FROM TreeCount\n",
    "ORDER BY tree_count DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "# File path for saving the query\n",
    "QUERY_5_FILENAME = QUERY_DIR / \"greenery_areas_with_spatial_join.sql\"\n",
    "\n",
    "# Execute the query and print the results\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(QUERY_5))\n",
    "    for row in result:\n",
    "        print(row)\n",
    "\n",
    "# Write the query to a file\n",
    "write_query_to_file(QUERY_5, QUERY_5_FILENAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9b5bed",
   "metadata": {},
   "source": [
    "### Query 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0abc857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 6: Finding trees within a ½ mile radius of a specific coordinate point\n",
    "# This query identifies which trees are within a ½ mile radius of the given latitude and longitude\n",
    "\n",
    "QUERY_6 = \"\"\"\n",
    "SELECT id, species, health, status, geom\n",
    "FROM tree_data\n",
    "WHERE ST_DWithin(\n",
    "    geom,\n",
    "    ST_SetSRID(ST_MakePoint(-73.96253174434912, 40.80737875669467), 4326),\n",
    "    0.5 * 1609.34  -- 0.5 miles in meters\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# File path for saving the query\n",
    "QUERY_6_FILENAME = QUERY_DIR / \"trees_nearby_coordinate.sql\"\n",
    "\n",
    "# Execute the query and print the results\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(QUERY_6))\n",
    "    for row in result:\n",
    "        print(row)\n",
    "\n",
    "# Write the query to a file\n",
    "write_query_to_file(QUERY_6, QUERY_6_FILENAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75223ce5-6ab5-4613-b6af-fa8e33bcc7d5",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21fcfed-ddbb-4908-a60e-ed7cbc6d5b00",
   "metadata": {},
   "source": [
    "### Visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0e2cde-e43b-407b-ab93-ff85a2dba469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a more descriptive name for your function\n",
    "def plot_visual_1(dataframe):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
    "    \n",
    "    # you may want to use matplotlib to plot your visualizations;\n",
    "    # there are also many other plot types (other \n",
    "    # than axes.plot) you can use\n",
    "    axes.plot(values, \"...\")\n",
    "    # there are other methods to use to label your axes, to style \n",
    "    # and set up axes labels, etc\n",
    "    axes.set_title(\"Some Descriptive Title\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed80755f-d1e1-4e53-8ef8-f5295c59a3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_1():\n",
    "    # Query your database for the data needed.\n",
    "    # You can put the data queried into a pandas/geopandas dataframe, if you wish\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a2632a-b516-4a6e-8b67-97116ab6fce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_1()\n",
    "plot_visual_1(some_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
