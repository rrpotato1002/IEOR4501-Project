{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13ccb856",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xX3rCbSDM4vF0QEfgh09b2ZWW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30ee2d8",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b76277",
   "metadata": {},
   "source": [
    "#### Downloading data from NYC Open Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "725b10da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sodapy import Socrata\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "976f1b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"\"\"\n",
    "select * \n",
    "where\n",
    "    created_date between '2023-01-01T00:00:00.000' \n",
    "    and '2023-05-27T04:23:00.001'\n",
    "\"\"\"\n",
    "#'2015-01-31T00:00:00.000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47c64422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 100000 of 10000000\n",
      "Downloaded 200000 of 10000000\n",
      "Downloaded 300000 of 10000000\n",
      "Downloaded 400000 of 10000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "from requests.exceptions import ReadTimeout\n",
    "from sodapy import Socrata\n",
    "\n",
    "# Example authenticated client (needed for non-public datasets):\n",
    "client = Socrata( \"data.cityofnewyork.us\",\n",
    "                  \"xX3rCbSDM4vF0QEfgh09b2ZWW\",\n",
    "                  username=\"yirong263@gmail.com\",\n",
    "                  password=\"UTDYnmz*zn2u3g6\",\n",
    "                  timeout=60)\n",
    "# Variables for retry logic\n",
    "max_retries = 5\n",
    "retry_wait = 10  # Initial wait time in seconds\n",
    "\n",
    "while max_retries > 0:\n",
    "    try:    \n",
    "    # Set initial parameters for the SoQL query\n",
    "        limit = 100000  # Example limit\n",
    "        offset = 0  # Start at the beginning\n",
    "        total_records = 10000000  # Example total number of records you wish to download\n",
    "        current_record = 0\n",
    "        while current_record < total_records:\n",
    "            # Adjust the query to include the limit and offset\n",
    "            results = client.get(\"erm2-nwe9\",query=query+ f\" limit {limit} offset {offset}\")\n",
    "            \n",
    "            # Convert to DataFrame and save to CSV\n",
    "            df = pd.DataFrame.from_records(results)\n",
    "            df.to_csv(f'nyc_311_data_part_2023_7_11_{offset // limit + 1}.csv', index=False)\n",
    "            \n",
    "            # Update the offset and current_record count\n",
    "            offset += limit\n",
    "            current_record += len(results)\n",
    "\n",
    "            # Optional: Print progress\n",
    "            print(f'Downloaded {current_record} of {total_records}')\n",
    "        break\n",
    "    \n",
    "    except ReadTimeout:\n",
    "        # Wait before retrying\n",
    "        time.sleep(retry_wait)\n",
    "        # Reduce the number of retries left\n",
    "        max_retries -= 1\n",
    "        # Increase the wait time for the next retry\n",
    "        retry_wait *= 2\n",
    "\n",
    "\n",
    "#results = client.get(\"erm2-nwe9\",query=query)\n",
    "# Convert to pandas DataFrame\n",
    "#NYC_311df = pd.DataFrame.from_records(results)\n",
    "#print(NYC_311df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcc23b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unique_key', 'created_date', 'closed_date', 'agency', 'agency_name', 'complaint_type', 'descriptor', 'location_type', 'incident_zip', 'incident_address', 'street_name', 'cross_street_1', 'cross_street_2', 'intersection_street_1', 'intersection_street_2', 'address_type', 'city', 'landmark', 'status', 'resolution_description', 'resolution_action_updated_date', 'community_board', 'bbl', 'borough', 'x_coordinate_state_plane', 'y_coordinate_state_plane', 'open_data_channel_type', 'park_facility_name', 'park_borough', 'latitude', 'longitude', 'location', 'taxi_pick_up_location', 'facility_type', 'bridge_highway_name', 'bridge_highway_segment', 'bridge_highway_direction', 'road_ramp', 'due_date']\n"
     ]
    }
   ],
   "source": [
    "# Convert the column names to a list and print them\n",
    "column_names = NYC_311df.columns.tolist()\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dac599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  unique_key             created_date              complaint_type  \\\n",
      "0   58970426  2023-09-30T00:00:00.000              Food Poisoning   \n",
      "1   58958037  2023-09-29T23:59:53.000         Noise - Residential   \n",
      "2   58963337  2023-09-29T23:59:40.000  For Hire Vehicle Complaint   \n",
      "3   58967293  2023-09-29T23:59:10.000         Noise - Residential   \n",
      "4   58957297  2023-09-29T23:59:00.000  For Hire Vehicle Complaint   \n",
      "\n",
      "                location_type incident_zip address_type      city  \\\n",
      "0            Food Cart Vendor        10003      ADDRESS  NEW YORK   \n",
      "1  Residential Building/House        11433      ADDRESS   JAMAICA   \n",
      "2                      Street        10002      ADDRESS  NEW YORK   \n",
      "3  Residential Building/House        11216      ADDRESS  BROOKLYN   \n",
      "4                      Street        10002      ADDRESS  NEW YORK   \n",
      "\n",
      "            landmark       status            latitude           longitude  \\\n",
      "0  UNION SQUARE EAST       Closed    40.7348900594353  -73.98994355524363   \n",
      "1         160 STREET       Closed  40.696276248515204  -73.79372227601002   \n",
      "2    CHRYSTIE STREET  In Progress  40.723202995922456  -73.99124770125584   \n",
      "3      ALBANY AVENUE       Closed    40.6805991000235  -73.93848100682325   \n",
      "4    CHRYSTIE STREET       Closed  40.723202995922456  -73.99124770125584   \n",
      "\n",
      "                                            location  \n",
      "0  {'latitude': '40.7348900594353', 'longitude': ...  \n",
      "1  {'latitude': '40.696276248515204', 'longitude'...  \n",
      "2  {'latitude': '40.723202995922456', 'longitude'...  \n",
      "3  {'latitude': '40.6805991000235', 'longitude': ...  \n",
      "4  {'latitude': '40.723202995922456', 'longitude'...  \n"
     ]
    }
   ],
   "source": [
    "columns_needed = ['unique_key', 'created_date', 'complaint_type','location_type','incident_zip','address_type', 'city', 'landmark', 'status','latitude', 'longitude', 'location']  # Replace with actual column names\n",
    "NYC_311df = NYC_311df[columns_needed]\n",
    "print(NYC_311df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de2baca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary columns by keeping only the ones you need\n",
    "columns_needed = ['unique_key', 'created_date', 'complaint_type','location_type','incident_zip','address_type', 'city', 'landmark', 'status','latitude', 'longitude', 'location']  # Replace with actual column names\n",
    "NYC_311df = NYC_311df[columns_needed]\n",
    "\n",
    "# Remove invalid data points\n",
    "# This is highly dependent on the context of your data, but as an example:\n",
    "NYC_311df.dropna(inplace=True)  # Drop rows where 'column1' or 'column2' is NaN\n",
    "\n",
    "# Normalize column names\n",
    "NYC_311df.columns = [column_name.lower().replace(' ', '_') for column_name in NYC_311df.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85944079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     created_at tree_id block_id  \\\n",
      "0    08/27/2015  180683   348711   \n",
      "1    09/03/2015  200540   315986   \n",
      "2    09/05/2015  204026   218365   \n",
      "3    09/05/2015  204337   217969   \n",
      "4    08/30/2015  189565   223043   \n",
      "..          ...     ...      ...   \n",
      "995  08/31/2015  191374   415497   \n",
      "996  08/26/2015  177355   224301   \n",
      "997  09/01/2015  195035   229940   \n",
      "998  08/26/2015  177062   409315   \n",
      "999  08/30/2015  188662   312637   \n",
      "\n",
      "                                              the_geom tree_dbh stump_diam  \\\n",
      "0    {'type': 'Point', 'coordinates': [-73.84421521...        3          0   \n",
      "1    {'type': 'Point', 'coordinates': [-73.81867945...       21          0   \n",
      "2    {'type': 'Point', 'coordinates': [-73.93660770...        3          0   \n",
      "3    {'type': 'Point', 'coordinates': [-73.93445615...       10          0   \n",
      "4    {'type': 'Point', 'coordinates': [-73.97597938...       21          0   \n",
      "..                                                 ...      ...        ...   \n",
      "995  {'type': 'Point', 'coordinates': [-74.12944305...        1          0   \n",
      "996  {'type': 'Point', 'coordinates': [-74.00015215...       10          0   \n",
      "997  {'type': 'Point', 'coordinates': [-73.95751667...       25          0   \n",
      "998  {'type': 'Point', 'coordinates': [-74.09660153...       18          0   \n",
      "999  {'type': 'Point', 'coordinates': [-73.79587098...       32          0   \n",
      "\n",
      "    curb_loc status health                           spc_latin  ... st_assem  \\\n",
      "0     OnCurb  Alive   Fair                         Acer rubrum  ...       28   \n",
      "1     OnCurb  Alive   Fair                   Quercus palustris  ...       27   \n",
      "2     OnCurb  Alive   Good  Gleditsia triacanthos var. inermis  ...       50   \n",
      "3     OnCurb  Alive   Good  Gleditsia triacanthos var. inermis  ...       53   \n",
      "4     OnCurb  Alive   Good                     Tilia americana  ...       44   \n",
      "..       ...    ...    ...                                 ...  ...      ...   \n",
      "995   OnCurb   Dead    NaN                                 NaN  ...       62   \n",
      "996   OnCurb  Alive   Poor                    Acer platanoides  ...       52   \n",
      "997   OnCurb  Alive   Good                    Acer platanoides  ...       48   \n",
      "998   OnCurb  Alive   Good                    Acer platanoides  ...       63   \n",
      "999   OnCurb  Alive   Fair                    Acer platanoides  ...       26   \n",
      "\n",
      "    st_senate   nta                                  nta_name  boro_ct  \\\n",
      "0          16  QN17                              Forest Hills  4073900   \n",
      "1          11  QN49                                Whitestone  4097300   \n",
      "2          18  BK90                         East Williamsburg  3044900   \n",
      "3          18  BK90                         East Williamsburg  3044900   \n",
      "4          21  BK37                        Park Slope-Gowanus  3016500   \n",
      "..        ...   ...                                       ...      ...   \n",
      "995        24  SI25                     Oakwood-Oakwood Beach  5013800   \n",
      "996        26  BK33  Carroll Gardens-Columbia Street-Red Hook  3006300   \n",
      "997        17  BK43                                   Midwood  3076200   \n",
      "998        24  SI36         Old Town-Dongan Hills-South Beach  5009602   \n",
      "999        11  QN51                               Murray Hill  4114100   \n",
      "\n",
      "        state     latitude     longitude           x_sp           y_sp  \n",
      "0    New York  40.72309177  -73.84421522  1027431.14821  202756.768749  \n",
      "1    New York  40.79411067  -73.81867946  1034455.70109  228644.837379  \n",
      "2    New York  40.71758074   -73.9366077  1001822.83131  200716.891267  \n",
      "3    New York  40.71353749  -73.93445616  1002420.35833  199244.253136  \n",
      "4    New York  40.66677776  -73.97597938  990913.775046  182202.425999  \n",
      "..        ...          ...           ...            ...            ...  \n",
      "995  New York  40.56929363  -74.12944305  948287.567976   146712.05013  \n",
      "996  New York  40.68505281  -74.00015216  984207.800269  188859.639063  \n",
      "997  New York  40.62479203  -73.95751667   996043.10009  166907.823715  \n",
      "998  New York   40.5925856  -74.09660154  957421.094985  155186.117827  \n",
      "999  New York  40.76495852  -73.79587099  1040795.85999  218037.647308  \n",
      "\n",
      "[1000 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = client.get(\"5rq2-4hqu\")\n",
    "# Convert to pandas DataFrame\n",
    "tree_df = pd.DataFrame.from_records(results)\n",
    "print(tree_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef471ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['created_at', 'tree_id', 'block_id', 'the_geom', 'tree_dbh', 'stump_diam', 'curb_loc', 'status', 'health', 'spc_latin', 'spc_common', 'steward', 'guards', 'sidewalk', 'user_type', 'problems', 'root_stone', 'root_grate', 'root_other', 'trnk_wire', 'trnk_light', 'trnk_other', 'brnch_ligh', 'brnch_shoe', 'brnch_othe', 'address', 'zipcode', 'zip_city', 'cb_num', 'borocode', 'boroname', 'cncldist', 'st_assem', 'st_senate', 'nta', 'nta_name', 'boro_ct', 'state', 'latitude', 'longitude', 'x_sp', 'y_sp']\n"
     ]
    }
   ],
   "source": [
    "# Convert the column names to a list and print them\n",
    "column_names = tree_df.columns.tolist()\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934cec66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary columns by keeping only the ones you need\n",
    "columns_needed = ['created_at', 'tree_id', 'block_id', 'tree_dbh', 'stump_diam','latitude', 'longitude', 'x_sp', 'y_sp']  # Replace with actual column names\n",
    "tree_df = tree_df[columns_needed]\n",
    "\n",
    "# Remove invalid data points\n",
    "# This is highly dependent on the context of your data, but as an example:\n",
    "tree_df.dropna(inplace=True)  # Drop rows where 'column1' or 'column2' is NaN\n",
    "\n",
    "# Normalize column names\n",
    "tree_df.columns = [column_name.lower().replace(' ', '_') for column_name in tree_df.columns]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
